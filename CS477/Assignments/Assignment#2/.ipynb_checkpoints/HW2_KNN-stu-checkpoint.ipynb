{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871ba3e9-d81f-4457-a880-b4558c8a2438",
   "metadata": {},
   "source": [
    "### Developing the K Nearest Neighbors (KNN) Regression to Predict the Disease Progression of Diabetes\n",
    "\n",
    "In Lecture 8, we implemented a KNN algorithm for classification, which computed a `simple majority vote` of the nearest neighbors of each test sample. \n",
    "\n",
    "In Homework 2, we will implement a KNN-based regression algorithm, and the prediction of a test sample is computed based on the `mean of the target values` of its nearest neighbors.\n",
    "\n",
    "`The diabetes dataset has 442 patients. Ten variables, age, sex, body mass index, average blood pressure, and six blood serum measurements, were obtained for each sample. The response/target variable is a quantitative measure of disease progression one year after baseline.`\n",
    "\n",
    "\n",
    "[Task 1: Split the dataset](task1)\n",
    "\n",
    "[Task 2: Implement the KNN for regession](task2)\n",
    "\n",
    "[Task 3: Evaluate](task3)\n",
    "\n",
    "[Task 4: Explore the impact of different K](Task4)\n",
    "\n",
    "[Task 5: Improve KNN]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a0eee-a01e-4259-b89c-cdf9793759d4",
   "metadata": {},
   "source": [
    "#### Load the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bba0f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxian/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Data preparation\n",
    "db = ds.load_diabetes()\n",
    "X = db.data #feature vectors\n",
    "y = db.target #target values\n",
    "\n",
    "print(db['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9618b7f-c4a6-4084-9858-65b4625d920d",
   "metadata": {},
   "source": [
    "#### Task 1: Split the dataset into training (75%) and test sets (25%). 5 points. <a id=\"task1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d55fd9f-b9ce-47cd-959a-e5512c83e725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "# add your code here\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc585ba-f5ff-4d2e-ab0c-f9716d5d7292",
   "metadata": {},
   "source": [
    "#### Task 2: Implement the KNN algorithm for regression. 20 points. <a id=\"task2\">\n",
    "\n",
    "- for any input data sample, find its k nearest neighbors on the training set\n",
    "- the prediction function will calculate the mean target values of the K neareast neighbors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6340b",
   "metadata": {},
   "source": [
    "##### Task 2.1: Complete the following function to identify the K nearest neighbors of a given data sample. \n",
    "- return both the indices and Euclidean distances of the K nearest neighbors for a given query/new sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b744b4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data sample:\n",
      " [ 0.06713621  0.05068012 -0.04177375  0.01154374  0.0025589   0.00588854\n",
      "  0.04127682 -0.03949338 -0.0594727  -0.02178823]\n",
      "K nearest neighbors of x in the training set:\n",
      " [309 262 128 105 135] \n",
      "Their distances to the query:\n",
      " [0.0030955  0.005225   0.00563592 0.00712298 0.00905236]\n"
     ]
    }
   ],
   "source": [
    "def findKNgbs(X_train, x_query, K = 5):\n",
    "    '''find K nearest neighbors for a given data sample in X_train\n",
    "        \n",
    "        input:\n",
    "            X_train: training set\n",
    "            x_query: new data sample/a query\n",
    "            K: the number of neighbors\n",
    "        return:\n",
    "            indK: the indices of of the K nearest neighbors\n",
    "            disK: the distances of the K nearest neighbors to x_new          \n",
    "    '''\n",
    "    #add your code here\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "x = X_test[0]\n",
    "print('Input data sample:\\n', x)\n",
    "k_inx, k_dis = findKNgbs(X_train, x, K=5)\n",
    "print('K nearest neighbors of x in the training set:\\n', k_inx, '\\nTheir distances to the query:\\n',k_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e2a36",
   "metadata": {},
   "source": [
    "\n",
    "##### Task 2.2: Predict the target value for new data samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fd5653a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 91 154 112 244 102 191 220 110 119 248]\n",
      "True target values: [ 75. 128. 125. 332.  37. 121. 259.  72.  40. 281.]\n"
     ]
    }
   ],
   "source": [
    "def predict(X_in, X_train, y_train, K=5):\n",
    "    '''predict the target vlues for input queries\n",
    "        Input:\n",
    "            X_in: new data samples/queries. n*4. contains multiple data samples\n",
    "            X_train: the feature vectors of training samples\n",
    "            y_train: the target values of the training samples\n",
    "            K: the number of neighbors\n",
    "\n",
    "        return:\n",
    "            y_pred: the predictions of the input queries\n",
    "    '''\n",
    "\n",
    "    #add your code here\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "n = 10 # 3 test samples\n",
    "K = 6 # k neighbors\n",
    "\n",
    "X_in = X_test[0:n]\n",
    "y_pred = predict(X_in, X_train, y_train, K)\n",
    "print('Predictions:', y_pred)\n",
    "print('True target values:', y_test[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc5572",
   "metadata": {},
   "source": [
    "#### Task 3: Evaluate the KNN method using MSE and MAE. 10 points. <a id=\"task3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc18e38",
   "metadata": {},
   "source": [
    "- Implement the mean square error(MSE) and mean absolute error(MAE) functions.\n",
    "- Calcualte the MSE and MAE of the knn on the test set\n",
    "\n",
    "    - MSE: ((y_true[0]-y_pred[0])**2 + ...+(y_true[n-1]-y_pred[n-1])**2))/n where n is the number of samples\n",
    "    - MAE: (|y_true[0]-y_pred[0]| + ...+|y_true[n-1]-y_pred[n-1]|)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "050d370a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the test set is 3620.64\n",
      "The MAE on the test set is 47.99\n"
     ]
    }
   ],
   "source": [
    "# calculate mean square error (MSE) between y_true and y_pred\n",
    "def myMSE(y_true, y_pred):\n",
    "    '''\n",
    "        y_true: the true target values\n",
    "        y_pred: predictions\n",
    "\n",
    "        return: the MSE between y_true and y_pred\n",
    "    '''    \n",
    "    #add your code here\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def myMAE(y_true, y_pred):\n",
    "    '''\n",
    "        y_true: the true target values\n",
    "        y_pred: predictions\n",
    "\n",
    "        return: the MAE between y_true and y_pred\n",
    "    '''    \n",
    "    #add your code here\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "y_pred = predict(X_test, X_train, y_train, K=4)\n",
    "mse = myMSE(y_test, y_pred)\n",
    "mae = myMAE(y_test, y_pred)\n",
    "print('The MSE on the test set is', round(mse, 2))\n",
    "print('The MAE on the test set is', round(mae, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152629e",
   "metadata": {},
   "source": [
    "#### Task 4: Explore the impact of different K. 10 points. <a id=\"task4\">\n",
    "    \n",
    "##### Task 4.1\n",
    "    - calculate the mse values for K from 1 to 30\n",
    "    - plot the mse values using a curve. Set the xlabel to 'K' and ylabel to 'MSE'. https://matplotlib.org/stable/gallery/pyplots/axline.html#sphx-glr-gallery-pyplots-axline-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba6a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt# evaluate the performance on the test set\n",
    "mses= []\n",
    "\n",
    "#add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea285b92",
   "metadata": {},
   "source": [
    "#### Task 4.2: Discuss your findings from the above curve, e.g., the trend, best K, and the impact of small and large Ks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae50db",
   "metadata": {},
   "source": [
    "Response: \n",
    "\n",
    "\\\n",
    "\\\n",
    "\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70bd01",
   "metadata": {},
   "source": [
    "#### Task 5: Improve the KNN method. 5 points. <a id=\"task5\">\n",
    "    - 10 extra points for implementing the imovement that can reduce the MSE or MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0882049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using K= 14 , the MSE on the test set is 3009.05\n",
      "Using K= 14 , the MAE on the test set is 44.53\n",
      "75.0 92\n",
      "128.0 129\n",
      "125.0 108\n",
      "332.0 216\n",
      "37.0 81\n",
      "121.0 167\n",
      "259.0 210\n",
      "72.0 98\n",
      "40.0 107\n",
      "281.0 240\n"
     ]
    }
   ],
   "source": [
    "k_best =14 # use your best K\n",
    "y_pred = predict(X_test, X_train, y_train, k_best)\n",
    "mse = myMSE(y_test, y_pred)\n",
    "print('Using K=', k_best, ', the MSE on the test set is', round(mse,2))\n",
    "mae = myMAE(y_test, y_pred)\n",
    "print('Using K=', k_best, ', the MAE on the test set is', round(mae, 2))\n",
    "\n",
    "# compare the predictions of the first 10 test samples and theirs true target values\n",
    "for i in range(10):\n",
    "    print(y_test[i], y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb8fff-75e8-4eb9-837c-e3bf4a90ac7a",
   "metadata": {},
   "source": [
    "From the above results, even we use the best K, the MSE and MAE are still large. Please suggest any possible improvements of the KNN alrorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194c0b5-0ca2-4aea-95d1-3fcbb4c57702",
   "metadata": {},
   "source": [
    "Response:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
