{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e157c5-620e-412b-a015-698a194bc256",
   "metadata": {},
   "source": [
    "***Andrew Plum***<br/>\n",
    "***CS 474***<br/>\n",
    "***11/18/2024***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e4d2a-bc6e-4530-92cd-2c6d9db4425c",
   "metadata": {},
   "source": [
    "## HW 5: Build a many-to-one RNN for sentiment analysis\n",
    "\n",
    "In this homework, you will build a many-to-one RNN for sentiment analysis, i.e., classify reviews into two categories: positive (1) and negative(0).\n",
    "\n",
    "**Dataset**: \n",
    "\n",
    "    -IMDb Movie Reviews for binary sentiment classification\n",
    "    -A set of 50,000 reviews with labels. All reviews have been cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1f1dad-2086-4144-a6b3-8d69791b5633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feel free to import other necassary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # you may need to install this package\n",
    "tqdm.pandas()\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1eead8-cf45-4a1b-9c56-e24975689f82",
   "metadata": {},
   "source": [
    "**For Keras Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a261ae0-ffcf-44e8-a254-0c624520a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam as Adam_tf\n",
    "from tensorflow.keras.layers import Dense, LSTM,Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5878efdd-0518-4bd0-856f-fc20e19deb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# For py3.11\\nimport os\\nos.environ['KERAS_BACKEND'] = 'tensorflow'\\n\\nfrom keras.models import Sequential\\nfrom keras.layers import LSTM, Dense\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# For py3.11\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e058e-5980-4195-b6a7-e52762709f77",
   "metadata": {},
   "source": [
    "**For PyTorch Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d183e6e-1179-479f-8a95-b3c08e9f6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam as Adam_torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b248e0-80bc-458e-944a-3ae010766d8d",
   "metadata": {},
   "source": [
    "#### 1. Load the dataset\n",
    "In the my_imdb.csv file, the 'review' column has preprocessed texts of user reviews, and the 'label' has binary catogories. 1 indicates positive comments, and 0 means negative comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c3d12a-d15d-402a-a7a6-7b48d1b5ad3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mentioned watching Oz episode hoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production . The filming te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonderful way spend time hot summer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically family little boy Jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love Time Money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  One reviewer mentioned watching Oz episode hoo...      1\n",
       "1  A wonderful little production . The filming te...      1\n",
       "2  I thought wonderful way spend time hot summer ...      1\n",
       "3  Basically family little boy Jake think zombie ...      0\n",
       "4  Petter Mattei Love Time Money visually stunnin...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read processed data\n",
    "df = pd.read_csv('my_imdb-1.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4e3f1-ac30-44da-b2eb-e0e6b37f6fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Text vectorization\n",
    "Text vectorization converts texts into sequences of numeric values\n",
    "\n",
    "- The **vocabulary** is a set that contains all unique words in the dataset.\n",
    "- The **vectorizer** is dictionary that contains every word in the vocabulary set and its index\n",
    "- The **padding** creates vectors with fixex length, e.g., 256\n",
    "- Feel free to change the following code to use other text vectorization approaches, e.g., TF-IDF or BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2956ba-7e2a-4e46-8b9a-6822c1e0600f",
   "metadata": {},
   "source": [
    "2.1 Create the vocabulary and the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6451ccd-934f-404d-adda-7a2565464dfe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1,\n",
       " ',': 2,\n",
       " 'I': 3,\n",
       " '-': 4,\n",
       " 'movie': 5,\n",
       " 'film': 6,\n",
       " 'The': 7,\n",
       " 'one': 8,\n",
       " '!': 9,\n",
       " 'like': 10,\n",
       " 'It': 11,\n",
       " '?': 12,\n",
       " 'time': 13,\n",
       " 'This': 14,\n",
       " 'good': 15,\n",
       " 'character': 16,\n",
       " 'story': 17,\n",
       " 'would': 18,\n",
       " 'get': 19,\n",
       " 'make': 20,\n",
       " 'see': 21,\n",
       " 'really': 22,\n",
       " 'even': 23,\n",
       " 'scene': 24,\n",
       " 'much': 25,\n",
       " 'well': 26,\n",
       " 'people': 27,\n",
       " 'bad': 28,\n",
       " 'great': 29,\n",
       " 'way': 30,\n",
       " 'show': 31,\n",
       " 'made': 32,\n",
       " 'thing': 33,\n",
       " 'first': 34,\n",
       " 'also': 35,\n",
       " 'could': 36,\n",
       " 'think': 37,\n",
       " 'life': 38,\n",
       " 'But': 39,\n",
       " 'know': 40,\n",
       " 'go': 41,\n",
       " 'And': 42,\n",
       " 'plot': 43,\n",
       " 'seen': 44,\n",
       " 'actor': 45,\n",
       " 'watch': 46,\n",
       " 'A': 47,\n",
       " 'say': 48,\n",
       " 'year': 49,\n",
       " 'love': 50,\n",
       " 'many': 51,\n",
       " 'end': 52,\n",
       " 'two': 53,\n",
       " 'acting': 54,\n",
       " 'look': 55,\n",
       " 'never': 56,\n",
       " 'There': 57,\n",
       " 'In': 58,\n",
       " 'little': 59,\n",
       " 'best': 60,\n",
       " 'ever': 61,\n",
       " 'better': 62,\n",
       " 'work': 63,\n",
       " 'If': 64,\n",
       " 'take': 65,\n",
       " 'come': 66,\n",
       " 'He': 67,\n",
       " 'find': 68,\n",
       " 'man': 69,\n",
       " 'part': 70,\n",
       " 'still': 71,\n",
       " 'something': 72,\n",
       " 'want': 73,\n",
       " 'give': 74,\n",
       " 'back': 75,\n",
       " 'lot': 76,\n",
       " 'real': 77,\n",
       " 'performance': 78,\n",
       " 'director': 79,\n",
       " 'play': 80,\n",
       " 'watching': 81,\n",
       " 'guy': 82,\n",
       " 'funny': 83,\n",
       " 'woman': 84,\n",
       " 'old': 85,\n",
       " 'role': 86,\n",
       " 'going': 87,\n",
       " 'actually': 88,\n",
       " 'though': 89,\n",
       " 'point': 90,\n",
       " 'cast': 91,\n",
       " 'nothing': 92,\n",
       " 'another': 93,\n",
       " 'minute': 94,\n",
       " 'thought': 95,\n",
       " 'fact': 96,\n",
       " 'feel': 97,\n",
       " 'girl': 98,\n",
       " 'comedy': 99,\n",
       " 'around': 100,\n",
       " 'quite': 101,\n",
       " 'got': 102,\n",
       " 'every': 103,\n",
       " 'action': 104,\n",
       " 'seems': 105,\n",
       " 'pretty': 106,\n",
       " 'horror': 107,\n",
       " 'day': 108,\n",
       " 'enough': 109,\n",
       " 'u': 110,\n",
       " 'You': 111,\n",
       " 'world': 112,\n",
       " 'bit': 113,\n",
       " 'right': 114,\n",
       " 'As': 115,\n",
       " 'line': 116,\n",
       " 'What': 117,\n",
       " 'They': 118,\n",
       " 'long': 119,\n",
       " 'fan': 120,\n",
       " 'series': 121,\n",
       " 'young': 122,\n",
       " 'friend': 123,\n",
       " 'must': 124,\n",
       " 'original': 125,\n",
       " 'set': 126,\n",
       " 'may': 127,\n",
       " 'always': 128,\n",
       " 'script': 129,\n",
       " 'saw': 130,\n",
       " 'music': 131,\n",
       " 'done': 132,\n",
       " 'least': 133,\n",
       " 'whole': 134,\n",
       " 'interesting': 135,\n",
       " 'family': 136,\n",
       " 'without': 137,\n",
       " 'almost': 138,\n",
       " 'big': 139,\n",
       " 'star': 140,\n",
       " 'try': 141,\n",
       " 'shot': 142,\n",
       " 'new': 143,\n",
       " 'far': 144,\n",
       " 'kind': 145,\n",
       " 'effect': 146,\n",
       " 'might': 147,\n",
       " 'making': 148,\n",
       " 'reason': 149,\n",
       " 'start': 150,\n",
       " 'anything': 151,\n",
       " 'kid': 152,\n",
       " 'TV': 153,\n",
       " 'book': 154,\n",
       " 'place': 155,\n",
       " 'put': 156,\n",
       " 'moment': 157,\n",
       " 'So': 158,\n",
       " 'She': 159,\n",
       " 'away': 160,\n",
       " 'probably': 161,\n",
       " 'last': 162,\n",
       " 'fun': 163,\n",
       " 'That': 164,\n",
       " 'idea': 165,\n",
       " 'audience': 166,\n",
       " 'found': 167,\n",
       " 'played': 168,\n",
       " 'screen': 169,\n",
       " 'child': 170,\n",
       " 'since': 171,\n",
       " 'need': 172,\n",
       " 'rather': 173,\n",
       " 'hard': 174,\n",
       " 'tell': 175,\n",
       " 'worst': 176,\n",
       " 'turn': 177,\n",
       " 'ending': 178,\n",
       " 'course': 179,\n",
       " 'looking': 180,\n",
       " 'DVD': 181,\n",
       " 'anyone': 182,\n",
       " 'When': 183,\n",
       " 'believe': 184,\n",
       " 'trying': 185,\n",
       " 'episode': 186,\n",
       " 'mean': 187,\n",
       " 'job': 188,\n",
       " 'yet': 189,\n",
       " 'different': 190,\n",
       " 'One': 191,\n",
       " 'especially': 192,\n",
       " 'main': 193,\n",
       " 'sense': 194,\n",
       " 'version': 195,\n",
       " 'American': 196,\n",
       " 'sure': 197,\n",
       " 'problem': 198,\n",
       " 'worth': 199,\n",
       " 'watched': 200,\n",
       " 'money': 201,\n",
       " 'help': 202,\n",
       " 'keep': 203,\n",
       " 'together': 204,\n",
       " 'someone': 205,\n",
       " 'said': 206,\n",
       " 'seem': 207,\n",
       " 'For': 208,\n",
       " 'laugh': 209,\n",
       " 'mind': 210,\n",
       " 'let': 211,\n",
       " 'three': 212,\n",
       " 'John': 213,\n",
       " 'wife': 214,\n",
       " 'hour': 215,\n",
       " 'true': 216,\n",
       " 'half': 217,\n",
       " 'All': 218,\n",
       " 'My': 219,\n",
       " 'lead': 220,\n",
       " 'left': 221,\n",
       " 'We': 222,\n",
       " 'short': 223,\n",
       " 'everything': 224,\n",
       " 'second': 225,\n",
       " 'special': 226,\n",
       " 'Not': 227,\n",
       " 'beautiful': 228,\n",
       " 'name': 229,\n",
       " 'else': 230,\n",
       " 'seeing': 231,\n",
       " 'budget': 232,\n",
       " 'viewer': 233,\n",
       " 'everyone': 234,\n",
       " 'later': 235,\n",
       " 'piece': 236,\n",
       " 'high': 237,\n",
       " 'used': 238,\n",
       " 'excellent': 239,\n",
       " 'However': 240,\n",
       " 'boy': 241,\n",
       " 'classic': 242,\n",
       " 'face': 243,\n",
       " 'production': 244,\n",
       " 'read': 245,\n",
       " 'le': 246,\n",
       " 'sound': 247,\n",
       " 'completely': 248,\n",
       " 'father': 249,\n",
       " 'camera': 250,\n",
       " 'death': 251,\n",
       " 'simply': 252,\n",
       " 'nice': 253,\n",
       " 'eye': 254,\n",
       " 'Hollywood': 255,\n",
       " 'top': 256,\n",
       " 'couple': 257,\n",
       " 'human': 258,\n",
       " 'word': 259,\n",
       " 'poor': 260,\n",
       " 'home': 261,\n",
       " 'use': 262,\n",
       " 'song': 263,\n",
       " 'hand': 264,\n",
       " 'low': 265,\n",
       " 'video': 266,\n",
       " 'head': 267,\n",
       " 'either': 268,\n",
       " 'rest': 269,\n",
       " 'boring': 270,\n",
       " 'wrong': 271,\n",
       " 'along': 272,\n",
       " 'night': 273,\n",
       " 'enjoy': 274,\n",
       " 'person': 275,\n",
       " 'recommend': 276,\n",
       " 'school': 277,\n",
       " 'style': 278,\n",
       " 'given': 279,\n",
       " 'stupid': 280,\n",
       " 'picture': 281,\n",
       " 'men': 282,\n",
       " 'writer': 283,\n",
       " 'understand': 284,\n",
       " 'truly': 285,\n",
       " 'war': 286,\n",
       " 'came': 287,\n",
       " 'sort': 288,\n",
       " 'sex': 289,\n",
       " 'dialogue': 290,\n",
       " 'No': 291,\n",
       " 'flick': 292,\n",
       " 'getting': 293,\n",
       " 'awful': 294,\n",
       " 'run': 295,\n",
       " 'house': 296,\n",
       " 'instead': 297,\n",
       " 'full': 298,\n",
       " 'joke': 299,\n",
       " 'case': 300,\n",
       " 'attempt': 301,\n",
       " 'hope': 302,\n",
       " 'black': 303,\n",
       " 'game': 304,\n",
       " 'kill': 305,\n",
       " 'playing': 306,\n",
       " 'care': 307,\n",
       " 'sequence': 308,\n",
       " 'Well': 309,\n",
       " 'next': 310,\n",
       " 'After': 311,\n",
       " 'title': 312,\n",
       " 'act': 313,\n",
       " 'At': 314,\n",
       " 'To': 315,\n",
       " 'terrible': 316,\n",
       " 'however': 317,\n",
       " 'small': 318,\n",
       " 'remember': 319,\n",
       " 'although': 320,\n",
       " 'maybe': 321,\n",
       " 'review': 322,\n",
       " 'Even': 323,\n",
       " 'fall': 324,\n",
       " 'mother': 325,\n",
       " 'often': 326,\n",
       " 'drama': 327,\n",
       " 'wonderful': 328,\n",
       " 'others': 329,\n",
       " 'quality': 330,\n",
       " 'perfect': 331,\n",
       " 'early': 332,\n",
       " 'written': 333,\n",
       " 'went': 334,\n",
       " 'THE': 335,\n",
       " 'example': 336,\n",
       " 'feeling': 337,\n",
       " 'become': 338,\n",
       " 'liked': 339,\n",
       " 'actress': 340,\n",
       " 'entertaining': 341,\n",
       " 'called': 342,\n",
       " 'felt': 343,\n",
       " 'car': 344,\n",
       " 'supposed': 345,\n",
       " 'matter': 346,\n",
       " 'entire': 347,\n",
       " 'waste': 348,\n",
       " 'side': 349,\n",
       " 'art': 350,\n",
       " 'cinema': 351,\n",
       " 'Mr': 352,\n",
       " 'absolutely': 353,\n",
       " 'worse': 354,\n",
       " 'lack': 355,\n",
       " 'feature': 356,\n",
       " 'beginning': 357,\n",
       " 'live': 358,\n",
       " 'comment': 359,\n",
       " 'Don': 360,\n",
       " 'His': 361,\n",
       " 'certainly': 362,\n",
       " 'definitely': 363,\n",
       " 'begin': 364,\n",
       " 'type': 365,\n",
       " 'direction': 366,\n",
       " 'loved': 367,\n",
       " 'favorite': 368,\n",
       " 'Then': 369,\n",
       " 'humor': 370,\n",
       " 'seemed': 371,\n",
       " 'While': 372,\n",
       " 'wanted': 373,\n",
       " 'several': 374,\n",
       " 'killer': 375,\n",
       " 'son': 376,\n",
       " 'Also': 377,\n",
       " 'fight': 378,\n",
       " 'change': 379,\n",
       " 'relationship': 380,\n",
       " 'already': 381,\n",
       " 'becomes': 382,\n",
       " 'voice': 383,\n",
       " 'totally': 384,\n",
       " 'based': 385,\n",
       " 'able': 386,\n",
       " 'dead': 387,\n",
       " 'genre': 388,\n",
       " 'hit': 389,\n",
       " 'Of': 390,\n",
       " 'Why': 391,\n",
       " 'experience': 392,\n",
       " 'guess': 393,\n",
       " 'heart': 394,\n",
       " 'Now': 395,\n",
       " 'hero': 396,\n",
       " 'Some': 397,\n",
       " 'brother': 398,\n",
       " 'Michael': 399,\n",
       " 'number': 400,\n",
       " 'writing': 401,\n",
       " 'lost': 402,\n",
       " 'meet': 403,\n",
       " 'daughter': 404,\n",
       " 'murder': 405,\n",
       " 'group': 406,\n",
       " 'fine': 407,\n",
       " 'throughout': 408,\n",
       " 'town': 409,\n",
       " 'history': 410,\n",
       " 'stop': 411,\n",
       " 'talent': 412,\n",
       " 'cut': 413,\n",
       " 'move': 414,\n",
       " 'etc': 415,\n",
       " 'today': 416,\n",
       " 'past': 417,\n",
       " 'How': 418,\n",
       " 'enjoyed': 419,\n",
       " 'gave': 420,\n",
       " 'close': 421,\n",
       " 'final': 422,\n",
       " 'stuff': 423,\n",
       " 'event': 424,\n",
       " 'situation': 425,\n",
       " 'level': 426,\n",
       " 'amazing': 427,\n",
       " 'finally': 428,\n",
       " 'credit': 429,\n",
       " 'theme': 430,\n",
       " 'expect': 431,\n",
       " 'horrible': 432,\n",
       " 'call': 433,\n",
       " 'behind': 434,\n",
       " 'stand': 435,\n",
       " 'age': 436,\n",
       " 'self': 437,\n",
       " 'late': 438,\n",
       " 'With': 439,\n",
       " 'killed': 440,\n",
       " 'white': 441,\n",
       " 'chance': 442,\n",
       " 'thinking': 443,\n",
       " 'perhaps': 444,\n",
       " 'evil': 445,\n",
       " 'wonder': 446,\n",
       " 'question': 447,\n",
       " 'New': 448,\n",
       " 'brilliant': 449,\n",
       " 'score': 450,\n",
       " 'decent': 451,\n",
       " 'body': 452,\n",
       " 'known': 453,\n",
       " 'took': 454,\n",
       " 'view': 455,\n",
       " 'directed': 456,\n",
       " 'Just': 457,\n",
       " 'happens': 458,\n",
       " 'heard': 459,\n",
       " 'dark': 460,\n",
       " 'career': 461,\n",
       " 'element': 462,\n",
       " 'novel': 463,\n",
       " 'documentary': 464,\n",
       " 'save': 465,\n",
       " 'light': 466,\n",
       " 'slow': 467,\n",
       " 'interest': 468,\n",
       " 'add': 469,\n",
       " 'involved': 470,\n",
       " 'On': 471,\n",
       " 'told': 472,\n",
       " 'husband': 473,\n",
       " 'effort': 474,\n",
       " 'coming': 475,\n",
       " 'power': 476,\n",
       " 'happen': 477,\n",
       " 'country': 478,\n",
       " 'David': 479,\n",
       " 'looked': 480,\n",
       " 'extremely': 481,\n",
       " 'opinion': 482,\n",
       " 'wish': 483,\n",
       " 'including': 484,\n",
       " 'B': 485,\n",
       " 'reality': 486,\n",
       " 'order': 487,\n",
       " 'leave': 488,\n",
       " 'obvious': 489,\n",
       " 'violence': 490,\n",
       " 'soon': 491,\n",
       " 'James': 492,\n",
       " 'sequel': 493,\n",
       " 'ago': 494,\n",
       " 'shown': 495,\n",
       " 'serious': 496,\n",
       " 'twist': 497,\n",
       " 'Robert': 498,\n",
       " 'particularly': 499,\n",
       " 'happened': 500,\n",
       " 'hilarious': 501,\n",
       " 'strong': 502,\n",
       " 'crap': 503,\n",
       " 'deal': 504,\n",
       " 'musical': 505,\n",
       " 'complete': 506,\n",
       " 'obviously': 507,\n",
       " 'talk': 508,\n",
       " 'Oh': 509,\n",
       " 'taken': 510,\n",
       " 'except': 511,\n",
       " 'value': 512,\n",
       " 'English': 513,\n",
       " 'female': 514,\n",
       " 'simple': 515,\n",
       " 'released': 516,\n",
       " 'opening': 517,\n",
       " 'across': 518,\n",
       " 'room': 519,\n",
       " 'Although': 520,\n",
       " 'thriller': 521,\n",
       " 'highly': 522,\n",
       " 'cool': 523,\n",
       " 'sometimes': 524,\n",
       " 'saying': 525,\n",
       " 'dialog': 526,\n",
       " 'exactly': 527,\n",
       " 'annoying': 528,\n",
       " 'whose': 529,\n",
       " 'monster': 530,\n",
       " 'theater': 531,\n",
       " 'sad': 532,\n",
       " 'started': 533,\n",
       " 'local': 534,\n",
       " 'turned': 535,\n",
       " 'possible': 536,\n",
       " 'cinematography': 537,\n",
       " 'important': 538,\n",
       " 'cop': 539,\n",
       " 'gore': 540,\n",
       " 'OK': 541,\n",
       " 'comic': 542,\n",
       " 'ridiculous': 543,\n",
       " 'message': 544,\n",
       " 'class': 545,\n",
       " 'Man': 546,\n",
       " 'sister': 547,\n",
       " 'living': 548,\n",
       " 'First': 549,\n",
       " 'open': 550,\n",
       " 'alone': 551,\n",
       " 'running': 552,\n",
       " 'despite': 553,\n",
       " 'police': 554,\n",
       " 'attention': 555,\n",
       " 'taking': 556,\n",
       " 'usual': 557,\n",
       " 'somewhat': 558,\n",
       " 'disappointed': 559,\n",
       " 'rating': 560,\n",
       " 'huge': 561,\n",
       " 'knew': 562,\n",
       " 'figure': 563,\n",
       " 'silly': 564,\n",
       " 'single': 565,\n",
       " 'talking': 566,\n",
       " 'blood': 567,\n",
       " 'mention': 568,\n",
       " 'surprise': 569,\n",
       " 'result': 570,\n",
       " 'member': 571,\n",
       " 'release': 572,\n",
       " 'producer': 573,\n",
       " 'non': 574,\n",
       " 'usually': 575,\n",
       " 'Jack': 576,\n",
       " 'hate': 577,\n",
       " 'dream': 578,\n",
       " 'mostly': 579,\n",
       " 'subject': 580,\n",
       " 'cheap': 581,\n",
       " 'middle': 582,\n",
       " 'parent': 583,\n",
       " 'team': 584,\n",
       " 'image': 585,\n",
       " 'British': 586,\n",
       " 'due': 587,\n",
       " 'television': 588,\n",
       " 'stay': 589,\n",
       " 'modern': 590,\n",
       " 'drug': 591,\n",
       " 'filmmaker': 592,\n",
       " 'happy': 593,\n",
       " 'form': 594,\n",
       " 'scary': 595,\n",
       " 'major': 596,\n",
       " 'From': 597,\n",
       " 'soundtrack': 598,\n",
       " 'viewing': 599,\n",
       " 'crime': 600,\n",
       " 'villain': 601,\n",
       " 'hold': 602,\n",
       " 'Maybe': 603,\n",
       " 'George': 604,\n",
       " 'appears': 605,\n",
       " 'doubt': 606,\n",
       " 'tale': 607,\n",
       " 'S': 608,\n",
       " 'upon': 609,\n",
       " 'seriously': 610,\n",
       " 'predictable': 611,\n",
       " 'dog': 612,\n",
       " 'moving': 613,\n",
       " 'enjoyable': 614,\n",
       " 'Yes': 615,\n",
       " 'strange': 616,\n",
       " 'aspect': 617,\n",
       " 'killing': 618,\n",
       " 'four': 619,\n",
       " 'Unfortunately': 620,\n",
       " 'romantic': 621,\n",
       " 'beyond': 622,\n",
       " 'similar': 623,\n",
       " 'hell': 624,\n",
       " 'giving': 625,\n",
       " 'break': 626,\n",
       " 'God': 627,\n",
       " 'clear': 628,\n",
       " 'future': 629,\n",
       " 'near': 630,\n",
       " 'clearly': 631,\n",
       " 'straight': 632,\n",
       " 'emotion': 633,\n",
       " 'entertainment': 634,\n",
       " 'easily': 635,\n",
       " 'surprised': 636,\n",
       " 'bring': 637,\n",
       " 'tried': 638,\n",
       " 'working': 639,\n",
       " 'showing': 640,\n",
       " 'city': 641,\n",
       " 'storyline': 642,\n",
       " 'adult': 643,\n",
       " 'setting': 644,\n",
       " 'ten': 645,\n",
       " 'none': 646,\n",
       " 'certain': 647,\n",
       " 'bunch': 648,\n",
       " 'suspense': 649,\n",
       " 'zombie': 650,\n",
       " 'dull': 651,\n",
       " 'named': 652,\n",
       " 'standard': 653,\n",
       " 'present': 654,\n",
       " 'buy': 655,\n",
       " 'victim': 656,\n",
       " 'fast': 657,\n",
       " 'season': 658,\n",
       " 'supporting': 659,\n",
       " 'filmed': 660,\n",
       " 'material': 661,\n",
       " 'Richard': 662,\n",
       " 'detail': 663,\n",
       " 'kept': 664,\n",
       " 'within': 665,\n",
       " 'student': 666,\n",
       " 'French': 667,\n",
       " 'Peter': 668,\n",
       " 'period': 669,\n",
       " 'easy': 670,\n",
       " 'realistic': 671,\n",
       " 'Dr': 672,\n",
       " 'th': 673,\n",
       " 'typical': 674,\n",
       " 'overall': 675,\n",
       " 'An': 676,\n",
       " 'Its': 677,\n",
       " 'Paul': 678,\n",
       " 'lady': 679,\n",
       " 'Oscar': 680,\n",
       " 'five': 681,\n",
       " 'gun': 682,\n",
       " 'issue': 683,\n",
       " 'premise': 684,\n",
       " 'editing': 685,\n",
       " 'return': 686,\n",
       " 'actual': 687,\n",
       " 'believable': 688,\n",
       " 'Like': 689,\n",
       " 'nearly': 690,\n",
       " 'using': 691,\n",
       " 'brought': 692,\n",
       " 'famous': 693,\n",
       " 'cartoon': 694,\n",
       " 'mystery': 695,\n",
       " 'among': 696,\n",
       " 'whether': 697,\n",
       " 'animation': 698,\n",
       " 'follow': 699,\n",
       " 'offer': 700,\n",
       " 'soldier': 701,\n",
       " 'Who': 702,\n",
       " 'fit': 703,\n",
       " 'Is': 704,\n",
       " 'America': 705,\n",
       " 'copy': 706,\n",
       " 'O': 707,\n",
       " 'Tom': 708,\n",
       " 'hear': 709,\n",
       " 'background': 710,\n",
       " 'greatest': 711,\n",
       " 'basically': 712,\n",
       " 'die': 713,\n",
       " 'stage': 714,\n",
       " 'atmosphere': 715,\n",
       " 'male': 716,\n",
       " 'Most': 717,\n",
       " 'weak': 718,\n",
       " 'masterpiece': 719,\n",
       " 'expected': 720,\n",
       " 'dance': 721,\n",
       " 'apparently': 722,\n",
       " 'average': 723,\n",
       " 'particular': 724,\n",
       " 'York': 725,\n",
       " 'fantastic': 726,\n",
       " 'learn': 727,\n",
       " 'sit': 728,\n",
       " 'Overall': 729,\n",
       " 'These': 730,\n",
       " 'pay': 731,\n",
       " 'battle': 732,\n",
       " 'rate': 733,\n",
       " 'decided': 734,\n",
       " 'Her': 735,\n",
       " 'note': 736,\n",
       " 'truth': 737,\n",
       " 'leaf': 738,\n",
       " 'choice': 739,\n",
       " 'romance': 740,\n",
       " 'miss': 741,\n",
       " 'rent': 742,\n",
       " 'escape': 743,\n",
       " 'difficult': 744,\n",
       " 'cover': 745,\n",
       " 'cause': 746,\n",
       " 'needed': 747,\n",
       " 'society': 748,\n",
       " 'box': 749,\n",
       " 'poorly': 750,\n",
       " 'Lee': 751,\n",
       " 'emotional': 752,\n",
       " 'acted': 753,\n",
       " 'footage': 754,\n",
       " 'gone': 755,\n",
       " 'crew': 756,\n",
       " 'accent': 757,\n",
       " 'focus': 758,\n",
       " 'D': 759,\n",
       " 'became': 760,\n",
       " 'week': 761,\n",
       " 'girlfriend': 762,\n",
       " 'street': 763,\n",
       " 'By': 764,\n",
       " 'forced': 765,\n",
       " 'King': 766,\n",
       " 'force': 767,\n",
       " 'yes': 768,\n",
       " 'write': 769,\n",
       " 'sexual': 770,\n",
       " 'War': 771,\n",
       " 'NOT': 772,\n",
       " 'free': 773,\n",
       " 'memorable': 774,\n",
       " 'space': 775,\n",
       " 'forward': 776,\n",
       " 'lame': 777,\n",
       " 'walk': 778,\n",
       " 'wait': 779,\n",
       " 'gay': 780,\n",
       " 'anyway': 781,\n",
       " 'Here': 782,\n",
       " 'location': 783,\n",
       " 'reading': 784,\n",
       " 'screenplay': 785,\n",
       " 'interested': 786,\n",
       " 'somehow': 787,\n",
       " 'lover': 788,\n",
       " 'T': 789,\n",
       " 'nature': 790,\n",
       " 'perfectly': 791,\n",
       " 'cheesy': 792,\n",
       " 'mess': 793,\n",
       " 'previous': 794,\n",
       " 'check': 795,\n",
       " 'Japanese': 796,\n",
       " 'touch': 797,\n",
       " 'forget': 798,\n",
       " 'personal': 799,\n",
       " 'maker': 800,\n",
       " 'quickly': 801,\n",
       " 'development': 802,\n",
       " 'third': 803,\n",
       " 'possibly': 804,\n",
       " 'imagine': 805,\n",
       " 'win': 806,\n",
       " 'worked': 807,\n",
       " 'superb': 808,\n",
       " 'please': 809,\n",
       " 'Disney': 810,\n",
       " 'realize': 811,\n",
       " 'badly': 812,\n",
       " 'remake': 813,\n",
       " 'general': 814,\n",
       " 'business': 815,\n",
       " 'unique': 816,\n",
       " 'deep': 817,\n",
       " 'earlier': 818,\n",
       " 'older': 819,\n",
       " 'Joe': 820,\n",
       " 'pick': 821,\n",
       " 'front': 822,\n",
       " 'sorry': 823,\n",
       " 'powerful': 824,\n",
       " 'IMDb': 825,\n",
       " 'amount': 826,\n",
       " 'appear': 827,\n",
       " 'dramatic': 828,\n",
       " 'weird': 829,\n",
       " 'success': 830,\n",
       " 'term': 831,\n",
       " 'match': 832,\n",
       " 'brings': 833,\n",
       " 'inside': 834,\n",
       " 'shame': 835,\n",
       " 'beauty': 836,\n",
       " 'towards': 837,\n",
       " 'teen': 838,\n",
       " 'shoot': 839,\n",
       " 'various': 840,\n",
       " 'admit': 841,\n",
       " 'incredibly': 842,\n",
       " 'fantasy': 843,\n",
       " 'Or': 844,\n",
       " 'hot': 845,\n",
       " 'directing': 846,\n",
       " 'portrayed': 847,\n",
       " 'doctor': 848,\n",
       " 'adventure': 849,\n",
       " 'creepy': 850,\n",
       " 'spent': 851,\n",
       " 'era': 852,\n",
       " 'party': 853,\n",
       " 'eventually': 854,\n",
       " 'political': 855,\n",
       " 'state': 856,\n",
       " 'memory': 857,\n",
       " 'Another': 858,\n",
       " 'fails': 859,\n",
       " 'total': 860,\n",
       " 'ask': 861,\n",
       " 'store': 862,\n",
       " 'portrayal': 863,\n",
       " 'costume': 864,\n",
       " 'fairly': 865,\n",
       " 'animal': 866,\n",
       " 'William': 867,\n",
       " 'deserves': 868,\n",
       " 'air': 869,\n",
       " 'wasted': 870,\n",
       " 'dumb': 871,\n",
       " 'leading': 872,\n",
       " 'telling': 873,\n",
       " 'concept': 874,\n",
       " 'studio': 875,\n",
       " 'Great': 876,\n",
       " 'rock': 877,\n",
       " 'list': 878,\n",
       " 'ability': 879,\n",
       " 'create': 880,\n",
       " 'meant': 881,\n",
       " 'fighting': 882,\n",
       " 'manages': 883,\n",
       " 'agree': 884,\n",
       " 'rich': 885,\n",
       " 'appearance': 886,\n",
       " 'ended': 887,\n",
       " 'expecting': 888,\n",
       " 'cry': 889,\n",
       " 'plenty': 890,\n",
       " 'depth': 891,\n",
       " 'company': 892,\n",
       " 'mistake': 893,\n",
       " 'secret': 894,\n",
       " 'indeed': 895,\n",
       " 'player': 896,\n",
       " 'missing': 897,\n",
       " 'water': 898,\n",
       " 'outside': 899,\n",
       " 'caught': 900,\n",
       " 'whatever': 901,\n",
       " 'talented': 902,\n",
       " 'Let': 903,\n",
       " 'pace': 904,\n",
       " 'German': 905,\n",
       " 'trouble': 906,\n",
       " 'Instead': 907,\n",
       " 'fire': 908,\n",
       " 'laughing': 909,\n",
       " 'crazy': 910,\n",
       " 'large': 911,\n",
       " 'language': 912,\n",
       " 'cute': 913,\n",
       " 'clever': 914,\n",
       " 'Italian': 915,\n",
       " 'plain': 916,\n",
       " 'created': 917,\n",
       " 'potential': 918,\n",
       " 'Black': 919,\n",
       " 'produced': 920,\n",
       " 'flat': 921,\n",
       " 'brain': 922,\n",
       " 'pull': 923,\n",
       " 'tension': 924,\n",
       " 'culture': 925,\n",
       " 'recently': 926,\n",
       " 'plan': 927,\n",
       " 'creature': 928,\n",
       " 'project': 929,\n",
       " 'mentioned': 930,\n",
       " 'wrote': 931,\n",
       " 'vampire': 932,\n",
       " 'Scott': 933,\n",
       " 'following': 934,\n",
       " 'control': 935,\n",
       " 'unless': 936,\n",
       " 'western': 937,\n",
       " 'missed': 938,\n",
       " 'fear': 939,\n",
       " 'stick': 940,\n",
       " 'nudity': 941,\n",
       " 'odd': 942,\n",
       " 'respect': 943,\n",
       " 'familiar': 944,\n",
       " 'hardly': 945,\n",
       " 'Good': 946,\n",
       " 'waiting': 947,\n",
       " 'slightly': 948,\n",
       " 'hole': 949,\n",
       " 'co': 950,\n",
       " 'Bill': 951,\n",
       " 'band': 952,\n",
       " 'drive': 953,\n",
       " 'Director': 954,\n",
       " 'World': 955,\n",
       " 'speak': 956,\n",
       " 'purpose': 957,\n",
       " 'public': 958,\n",
       " 'visual': 959,\n",
       " 'casting': 960,\n",
       " 'Movie': 961,\n",
       " 'filled': 962,\n",
       " 'decides': 963,\n",
       " 'us': 964,\n",
       " 'convincing': 965,\n",
       " 'popular': 966,\n",
       " 'throw': 967,\n",
       " 'Perhaps': 968,\n",
       " 'married': 969,\n",
       " 'Jane': 970,\n",
       " 'entirely': 971,\n",
       " 'Do': 972,\n",
       " 'fi': 973,\n",
       " 'door': 974,\n",
       " 'attack': 975,\n",
       " 'track': 976,\n",
       " 'color': 977,\n",
       " 'extra': 978,\n",
       " 'follows': 979,\n",
       " 'positive': 980,\n",
       " 'bored': 981,\n",
       " 'meaning': 982,\n",
       " 'appreciate': 983,\n",
       " 'died': 984,\n",
       " 'Star': 985,\n",
       " 'answer': 986,\n",
       " 'pure': 987,\n",
       " 'social': 988,\n",
       " 'belief': 989,\n",
       " 'unfortunately': 990,\n",
       " 'taste': 991,\n",
       " 'common': 992,\n",
       " 'intelligent': 993,\n",
       " 'younger': 994,\n",
       " 'former': 995,\n",
       " 'catch': 996,\n",
       " 'hair': 997,\n",
       " 'spirit': 998,\n",
       " 'building': 999,\n",
       " 'office': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all words\n",
    "text = df.review.values\n",
    "words = ' '.join(text)\n",
    "words = words.split() \n",
    "\n",
    "# build vocabulary\n",
    "vocab = sorted(Counter(words), key=Counter(words).get, reverse=True)\n",
    "ID2W = dict(enumerate(vocab, 1))\n",
    "ID2W[0] = '<PAD>' # special word for paddding purpose, and the index is 0\n",
    "vectorizer = {word: ID for ID, word in ID2W.items()}\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b342aa-3a75-4497-92b2-ebbe5696ee89",
   "metadata": {
    "tags": []
   },
   "source": [
    "2.2 Sample results of vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e079a8-0dfb-4267-b452-a7fe5c076955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text sample: One reviewer mentioned watching Oz episode hooked . They right , exactly happened . The first thing struck Oz brutality unflinching scene violence , set right word GO . Trust , show faint hearted timid . This show pull punch regard drug , sex violence . Its hardcore , classic use word . It called OZ nickname given Oswald Maximum Security State Penitentary . It focus mainly Emerald City , experimental section prison cell glass front face inwards , privacy high agenda . Em City home many . . Aryans , Muslims , gangsta , Latinos , Christians , Italians , Irish . . . . scuffle , death stare , dodgy dealing shady agreement never far away . I would say main appeal show due fact go show dare . Forget pretty picture painted mainstream audience , forget charm , forget romance . . . OZ mess around . The first episode I ever saw struck nasty surreal , I say I ready , I watched , I developed taste Oz , got accustomed high level graphic violence . Not violence , injustice crooked guard sold nickel , inmate kill order get away , well mannered , middle class inmate turned prison bitch due lack street skill prison experience Watching Oz , may become comfortable uncomfortable viewing . . . . thats get touch darker side .\n",
      "Coverted vector: 228 [191, 1083, 930, 81, 3724, 186, 3030, 1, 118, 114, 2, 527, 500, 1, 7, 34, 33, 3086, 3724, 5192, 15234, 24, 490, 2, 126, 114, 259, 7473, 1, 5550, 2, 31, 6620, 2169, 11285, 1, 14, 31, 923, 2106, 2177, 591, 2, 289, 490, 1, 677, 3805, 2, 242, 262, 259, 1, 11, 342, 9227, 10121, 279, 14927, 22637, 12715, 4100, 55917, 1, 11, 758, 1332, 29362, 1094, 2, 4665, 1963, 1105, 2317, 2079, 822, 243, 55918, 2, 16586, 237, 4338, 1, 18349, 1094, 261, 51, 1, 1, 25451, 2, 8327, 2, 12516, 2, 15235, 2, 5060, 2, 7897, 2, 2344, 1, 1, 1, 1, 22638, 2, 251, 4076, 2, 7347, 1674, 8574, 9867, 56, 144, 160, 1, 3, 18, 48, 193, 1066, 31, 587, 96, 41, 31, 2759, 1, 4156, 106, 281, 4057, 2373, 166, 2, 798, 1179, 2, 798, 740, 1, 1, 1, 9227, 793, 100, 1, 7, 34, 186, 3, 61, 130, 3086, 1520, 2117, 2, 3, 48, 3, 1457, 2, 3, 200, 2, 3, 1283, 991, 3724, 2, 102, 10122, 237, 426, 1295, 490, 1, 227, 490, 2, 6231, 7537, 2219, 2851, 21863, 2, 5136, 305, 487, 19, 160, 2, 26, 7405, 2, 582, 545, 5136, 535, 1105, 5438, 587, 355, 763, 1175, 1105, 392, 1947, 3724, 2, 127, 338, 3639, 3156, 599, 1, 1, 1, 1, 1645, 19, 797, 3941, 349, 1]\n"
     ]
    }
   ],
   "source": [
    "print('Text sample:', text[0])\n",
    "num_vec = [vectorizer[w] for w in text[0].split()]\n",
    "print('Coverted vector:',  len(num_vec), num_vec,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910d1dc-9ed3-45ee-bbd5-4a1eb4b9475c",
   "metadata": {
    "tags": []
   },
   "source": [
    "2.3 Apply vectorization to the whole dataset\n",
    "- Apply padding to create sequences with fixed length\n",
    "- The final dataset with with numeric features is (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b1774a-2f85-4968-9be8-c585b86cde90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 37697.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text vectors: (50000, 256)\n",
      "Labels: (50000,)\n"
     ]
    }
   ],
   "source": [
    "# text vectorization and padding\n",
    "vecs = [[vectorizer[w] for w in r.split()] for r in tqdm(text)] # vecs contains the vectorized reviews of varying length\n",
    "seq_length = 256\n",
    "    \n",
    "X = np.full((len(vecs), seq_length), 0, dtype=int) # create matrix whose shape is (50000, 256) initialized with 0\n",
    "for i, vec in enumerate(vecs): \n",
    "    X[i, :len(vec)] = np.array(vec)[:seq_length] # of each vectorized review, grab only up to the first 256 values and store in the row of X\n",
    "\n",
    "print('Text vectors:', X.shape)\n",
    "Y = df.label.to_numpy()\n",
    "print('Labels:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59002fa-fbe6-4100-8df0-35a0262234ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector:\n",
      " 291\n",
      "Results with padding:\n",
      " [  191  1083   930    81  3724   186  3030     1   118   114     2   527\n",
      "   500     1     7    34    33  3086  3724  5192 15234    24   490     2\n",
      "   126   114   259  7473     1  5550     2    31  6620  2169 11285     1\n",
      "    14    31   923  2106  2177   591     2   289   490     1   677  3805\n",
      "     2   242   262   259     1    11   342  9227 10121   279 14927 22637\n",
      " 12715  4100 55917     1    11   758  1332 29362  1094     2  4665  1963\n",
      "  1105  2317  2079   822   243 55918     2 16586   237  4338     1 18349\n",
      "  1094   261    51     1     1 25451     2  8327     2 12516     2 15235\n",
      "     2  5060     2  7897     2  2344     1     1     1     1 22638     2\n",
      "   251  4076     2  7347  1674  8574  9867    56   144   160     1     3\n",
      "    18    48   193  1066    31   587    96    41    31  2759     1  4156\n",
      "   106   281  4057  2373   166     2   798  1179     2   798   740     1\n",
      "     1     1  9227   793   100     1     7    34   186     3    61   130\n",
      "  3086  1520  2117     2     3    48     3  1457     2     3   200     2\n",
      "     3  1283   991  3724     2   102 10122   237   426  1295   490     1\n",
      "   227   490     2  6231  7537  2219  2851 21863     2  5136   305   487\n",
      "    19   160     2    26  7405     2   582   545  5136   535  1105  5438\n",
      "   587   355   763  1175  1105   392  1947  3724     2   127   338  3639\n",
      "  3156   599     1     1     1     1  1645    19   797  3941   349     1\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print('Original vector:\\n', vec[0])\n",
    "print('Results with padding:\\n', X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b94f4-2cd6-4c71-a395-e4103ed611fc",
   "metadata": {},
   "source": [
    "## Keras Implementation - Professor said we could implement using keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb29b4a-eea4-42e1-89c5-5e860bcf31f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Prepare the training, validation and test sets. 15 points\n",
    "- Use 50% data for training, 20% for validation, and 30% for testing\n",
    "- Set the batch size to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891f69a8-443b-487d-b466-8b9c56ce8cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "(25000, 256)\n",
      "(25000,)\n",
      "\n",
      "Validation set:\n",
      "(10000, 256)\n",
      "(10000,)\n",
      "\n",
      "Test set:\n",
      "(15000, 256)\n",
      "(15000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.5, random_state = 0)\n",
    "X_validation, X_test, Y_validation, Y_test = train_test_split(X_test, Y_test, test_size = 0.6, random_state = 0)\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print()\n",
    "print(\"Validation set:\")\n",
    "print(X_validation.shape)\n",
    "print(Y_validation.shape)\n",
    "print()\n",
    "print(\"Test set:\")\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print()\n",
    "\n",
    "# batch size set in next cell with other hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb9907",
   "metadata": {},
   "source": [
    "# Yours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6262dd-14ff-484f-bec8-6f31df046286",
   "metadata": {},
   "source": [
    "#### 4. Build a many-to-one RNN. 40 points\n",
    "- GRU or LSTM is preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4304411-2b20-44cb-bc7a-b1ef059d44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m TF_LSTM_RNN \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     18\u001b[0m TF_LSTM_RNN\u001b[38;5;241m.\u001b[39madd(LSTM(hidden_size, return_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, input_shape \u001b[38;5;241m=\u001b[39m (time_step, input_size)))\n\u001b[0;32m---> 19\u001b[0m TF_LSTM_RNN\u001b[38;5;241m.\u001b[39madd(LSTM(hidden_size))\n\u001b[1;32m     21\u001b[0m TF_LSTM_RNN\u001b[38;5;241m.\u001b[39madd(Dense(output_size, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \n\u001b[1;32m     23\u001b[0m TF_LSTM_RNN\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m Adam_tf(learning_rate \u001b[38;5;241m=\u001b[39m lr), loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/models/sequential.py:122\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_rebuild()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/models/sequential.py:141\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    140\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(input_shape)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     original_build_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/models/sequential.py:187\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:826\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m################\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# 4. Call build\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(call_spec)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# 5. Infer training value\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# Training phase for `Layer.call` is set via (in order of priority):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# across nested calls.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m call_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_call_context()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:1365\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, call_spec)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_default(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild):\n\u001b[1;32m   1359\u001b[0m     shapes_dict \u001b[38;5;241m=\u001b[39m update_shapes_dict_for_target_fn(\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild,\n\u001b[1;32m   1361\u001b[0m         shapes_dict\u001b[38;5;241m=\u001b[39mshapes_dict,\n\u001b[1;32m   1362\u001b[0m         call_spec\u001b[38;5;241m=\u001b[39mcall_spec,\n\u001b[1;32m   1363\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m   1364\u001b[0m     )\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mshapes_dict)\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;66;03m# Check input spec again (after build, since self.input_spec\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;66;03m# may have been updated\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_input_compatibility(call_spec\u001b[38;5;241m.\u001b[39mfirst_arg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     original_build_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:278\u001b[0m, in \u001b[0;36mRNN.build\u001b[0;34m(self, sequences_shape, initial_state_shape)\u001b[0m\n\u001b[1;32m    276\u001b[0m step_input_shape \u001b[38;5;241m=\u001b[39m (sequences_shape[\u001b[38;5;241m0\u001b[39m],) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sequences_shape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell, Layer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mbuild(step_input_shape)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     original_build_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py:153\u001b[0m, in \u001b[0;36mLSTMCell.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    145\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    147\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(input_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m    148\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_constraint,\n\u001b[1;32m    152\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    154\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecurrent_kernel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_initializer,\n\u001b[1;32m    157\u001b[0m     regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_regularizer,\n\u001b[1;32m    158\u001b[0m     constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_constraint,\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_forget_bias:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/layer.py:541\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, name)\u001b[0m\n\u001b[1;32m    539\u001b[0m initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(initializer)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 541\u001b[0m     variable \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[1;32m    542\u001b[0m         initializer\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[1;32m    543\u001b[0m         shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m    544\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    545\u001b[0m         trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m    546\u001b[0m         autocast\u001b[38;5;241m=\u001b[39mautocast,\n\u001b[1;32m    547\u001b[0m         aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m    548\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    549\u001b[0m     )\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# Will be added to layer.losses\u001b[39;00m\n\u001b[1;32m    551\u001b[0m variable\u001b[38;5;241m.\u001b[39mregularizer \u001b[38;5;241m=\u001b[39m regularizers\u001b[38;5;241m.\u001b[39mget(regularizer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/common/variables.py:163\u001b[0m, in \u001b[0;36mKerasVariable.__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape(shape)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_with_initializer(initializer)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(initializer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:40\u001b[0m, in \u001b[0;36mVariable._initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_with_initializer\u001b[39m(\u001b[38;5;28mself\u001b[39m, initializer):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype),\n\u001b[1;32m     42\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[1;32m     43\u001b[0m         trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable,\n\u001b[1;32m     44\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     45\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:198\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_variable_call\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_call):\n\u001b[0;32m--> 198\u001b[0m     variable_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:1230\u001b[0m, in \u001b[0;36mVariable._variable_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1229\u001b[0m   aggregation \u001b[38;5;241m=\u001b[39m VariableAggregation\u001b[38;5;241m.\u001b[39mNONE\n\u001b[0;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m previous_getter(\n\u001b[1;32m   1231\u001b[0m     initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[1;32m   1232\u001b[0m     trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m   1233\u001b[0m     validate_shape\u001b[38;5;241m=\u001b[39mvalidate_shape,\n\u001b[1;32m   1234\u001b[0m     caching_device\u001b[38;5;241m=\u001b[39mcaching_device,\n\u001b[1;32m   1235\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   1236\u001b[0m     variable_def\u001b[38;5;241m=\u001b[39mvariable_def,\n\u001b[1;32m   1237\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1238\u001b[0m     import_scope\u001b[38;5;241m=\u001b[39mimport_scope,\n\u001b[1;32m   1239\u001b[0m     constraint\u001b[38;5;241m=\u001b[39mconstraint,\n\u001b[1;32m   1240\u001b[0m     synchronization\u001b[38;5;241m=\u001b[39msynchronization,\n\u001b[1;32m   1241\u001b[0m     aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m   1242\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   1243\u001b[0m     experimental_enable_variable_lifting\u001b[38;5;241m=\u001b[39mexperimental_enable_variable_lifting,\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1245\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:1223\u001b[0m, in \u001b[0;36mVariable._variable_call.<locals>.<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Variable:\n\u001b[1;32m   1222\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m previous_getter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws: default_variable_creator_v2(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, getter \u001b[38;5;129;01min\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_stack:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m   previous_getter \u001b[38;5;241m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:51\u001b[0m, in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_variable_creator_v2\u001b[39m(next_creator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m resource_variable_ops\u001b[38;5;241m.\u001b[39mdefault_variable_creator_v2(\n\u001b[1;32m     52\u001b[0m       next_creator\u001b[38;5;241m=\u001b[39mnext_creator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:357\u001b[0m, in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m shape \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    354\u001b[0m experimental_enable_variable_lifting \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_enable_variable_lifting\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ResourceVariable(\n\u001b[1;32m    358\u001b[0m     initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[1;32m    359\u001b[0m     trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m    360\u001b[0m     validate_shape\u001b[38;5;241m=\u001b[39mvalidate_shape,\n\u001b[1;32m    361\u001b[0m     caching_device\u001b[38;5;241m=\u001b[39mcaching_device,\n\u001b[1;32m    362\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    363\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    364\u001b[0m     constraint\u001b[38;5;241m=\u001b[39mconstraint,\n\u001b[1;32m    365\u001b[0m     variable_def\u001b[38;5;241m=\u001b[39mvariable_def,\n\u001b[1;32m    366\u001b[0m     import_scope\u001b[38;5;241m=\u001b[39mimport_scope,\n\u001b[1;32m    367\u001b[0m     distribute_strategy\u001b[38;5;241m=\u001b[39mdistribute_strategy,\n\u001b[1;32m    368\u001b[0m     synchronization\u001b[38;5;241m=\u001b[39msynchronization,\n\u001b[1;32m    369\u001b[0m     aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m    370\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m    371\u001b[0m     experimental_enable_variable_lifting\u001b[38;5;241m=\u001b[39mexperimental_enable_variable_lifting,\n\u001b[1;32m    372\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/variables.py:201\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(VariableMetaclass, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:1873\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m   1868\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_handle(trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m   1869\u001b[0m                          shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   1870\u001b[0m                          dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1871\u001b[0m                          handle\u001b[38;5;241m=\u001b[39mhandle)\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_args(\n\u001b[1;32m   1874\u001b[0m       initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[1;32m   1875\u001b[0m       trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m   1876\u001b[0m       collections\u001b[38;5;241m=\u001b[39mcollections,\n\u001b[1;32m   1877\u001b[0m       caching_device\u001b[38;5;241m=\u001b[39mcaching_device,\n\u001b[1;32m   1878\u001b[0m       name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   1879\u001b[0m       dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1880\u001b[0m       constraint\u001b[38;5;241m=\u001b[39mconstraint,\n\u001b[1;32m   1881\u001b[0m       synchronization\u001b[38;5;241m=\u001b[39msynchronization,\n\u001b[1;32m   1882\u001b[0m       aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m   1883\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   1884\u001b[0m       distribute_strategy\u001b[38;5;241m=\u001b[39mdistribute_strategy,\n\u001b[1;32m   1885\u001b[0m       validate_shape\u001b[38;5;241m=\u001b[39mvalidate_shape,\n\u001b[1;32m   1886\u001b[0m       experimental_enable_variable_lifting\u001b[38;5;241m=\u001b[39mexperimental_enable_variable_lifting,\n\u001b[1;32m   1887\u001b[0m       )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:2057\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializer\u001b[39m\u001b[38;5;124m\"\u001b[39m), device_context_manager(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2056\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m init_from_fn:\n\u001b[0;32m-> 2057\u001b[0m     initial_value \u001b[38;5;241m=\u001b[39m initial_value()\n\u001b[1;32m   2058\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(initial_value, trackable\u001b[38;5;241m.\u001b[39mCheckpointInitialValue):\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:41\u001b[0m, in \u001b[0;36mVariable._initialize_with_initializer.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_with_initializer\u001b[39m(\u001b[38;5;28mself\u001b[39m, initializer):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype),\n\u001b[1;32m     42\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[1;32m     43\u001b[0m         trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable,\n\u001b[1;32m     44\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m     45\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/initializers/random_initializers.py:704\u001b[0m, in \u001b[0;36mOrthogonalInitializer.__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    702\u001b[0m a \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mnormal(flat_shape, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Compute the qr factorization\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m q, r \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mqr(a)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Make Q uniform\u001b[39;00m\n\u001b[1;32m    706\u001b[0m d \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mdiag(r)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/ops/linalg.py:444\u001b[0m, in \u001b[0;36mqr\u001b[0;34m(x, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Qr(mode\u001b[38;5;241m=\u001b[39mmode)\u001b[38;5;241m.\u001b[39msymbolic_call(x)\n\u001b[1;32m    443\u001b[0m x \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mqr(x, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/linalg.py:166\u001b[0m, in \u001b[0;36mqr\u001b[0;34m(x, mode)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`mode` argument value not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduced\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: mode=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduced\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mqr(x)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mqr(x, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/gen_linalg_ops.py:2189\u001b[0m, in \u001b[0;36mqr\u001b[0;34m(input, full_matrices, name)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   2188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2189\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m   2190\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQr\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m, full_matrices)\n\u001b[1;32m   2191\u001b[0m     _result \u001b[38;5;241m=\u001b[39m _QrOutput\u001b[38;5;241m.\u001b[39m_make(_result)\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = 256\n",
    "hidden_size = 512\n",
    "output_size = 1\n",
    "batch_size = 128\n",
    "time_step = 1\n",
    "lr = 0.0001\n",
    "\n",
    "# reshape data to include time_step\n",
    "\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], time_step, input_size)\n",
    "X_validation_reshaped = X_validation.reshape(X_validation.shape[0], time_step, input_size)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], time_step, input_size)\n",
    "\n",
    "# build keras LSTM RNN\n",
    "\n",
    "TF_LSTM_RNN = Sequential()\n",
    "\n",
    "TF_LSTM_RNN.add(LSTM(hidden_size, return_sequences = True, input_shape = (time_step, input_size)))\n",
    "TF_LSTM_RNN.add(LSTM(hidden_size))\n",
    "\n",
    "TF_LSTM_RNN.add(Dense(output_size, activation = \"sigmoid\")) \n",
    "\n",
    "TF_LSTM_RNN.compile(optimizer = Adam_tf(learning_rate = lr), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "TF_LSTM_RNN.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeccd98-f3ef-4be8-b0ca-c0aba2f5e8c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Train the above model. 30 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3628064-ae6d-4abe-950d-a3246a448d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.4972 - loss: 0.6945 - val_accuracy: 0.5085 - val_loss: 0.6938\n",
      "Epoch 2/15\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5587 - loss: 0.6864 - val_accuracy: 0.5091 - val_loss: 0.6946\n",
      "Epoch 3/15\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5742 - loss: 0.6806 - val_accuracy: 0.5143 - val_loss: 0.6966\n",
      "Epoch 4/15\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.5837 - loss: 0.6750 - val_accuracy: 0.5140 - val_loss: 0.7001\n",
      "Epoch 5/15\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.5956 - loss: 0.6699 - val_accuracy: 0.5094 - val_loss: 0.7029\n",
      "Epoch 6/15\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.5949 - loss: 0.6684 - val_accuracy: 0.5138 - val_loss: 0.7064\n",
      "Epoch 7/15\n",
      "\u001b[1m312/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6144 - loss: 0.6584"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m TF_LSTM_RNN_training_history \u001b[38;5;241m=\u001b[39m TF_LSTM_RNN\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, Y_train, validation_data \u001b[38;5;241m=\u001b[39m (X_validation_reshaped, Y_validation), epochs \u001b[38;5;241m=\u001b[39m num_epochs, batch_size \u001b[38;5;241m=\u001b[39m batch_size)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print train time\u001b[39;00m\n\u001b[1;32m      8\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m ((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "TF_LSTM_RNN_training_history = TF_LSTM_RNN.fit(X_train_reshaped, Y_train, validation_data = (X_validation_reshaped, Y_validation), epochs = num_epochs, batch_size = batch_size)\n",
    "\n",
    "# print train time\n",
    "elapsed_time = ((time.time() - start_time) / 60)\n",
    "print()\n",
    "print(\"Elapsed model training time:\\n{:.2f} minutes\".format(elapsed_time))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(TF_LSTM_RNN_training_history.history[\"loss\"], label = \"Training Loss\")\n",
    "plt.plot(TF_LSTM_RNN_training_history.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Losses of Keras LSTM RNN\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5de83-c9c6-4383-aa34-de0f5299360a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6. Calculate and report the performance of your model on the training and test set. 15 points\n",
    "- Calculate the accuracies on the training and test sets\n",
    "- Print out the confusion matrix of model results on the test set: https://scikit-learn.org/dev/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ac7b3-a5d7-4214-9ca4-897c3d54cd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 5ms/step\n",
      "469/469 [==============================] - 3s 6ms/step\n",
      "\n",
      "Using accuracy score:\n",
      "\n",
      "Training accuracy: 0.63016\n",
      "Test accuracy: 0.5258\n",
      "\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.6407 - accuracy: 0.6302\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.7094 - accuracy: 0.5258\n",
      "\n",
      "Using evaluate:\n",
      "\n",
      "Training accuracy: 0.6301599740982056\n",
      "Test accuracy: 0.5257999897003174\n",
      "Training loss 0.6406683325767517\n",
      "Test loss 0.7093936800956726\n",
      "\n",
      "Confusion matrix for train set:\n",
      " [[8275 4164]\n",
      " [5082 7479]]\n",
      "\n",
      "Confusion matrix for test set:\n",
      " [[4209 3314]\n",
      " [3799 3678]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "Y_train_hat = TF_LSTM_RNN.predict(X_train_reshaped)\n",
    "Y_test_hat = TF_LSTM_RNN.predict(X_test_reshaped)\n",
    "Y_train_hat = (Y_train_hat > 0.5).astype(int)\n",
    "Y_test_hat = (Y_test_hat > 0.5).astype(int)\n",
    "\n",
    "train_accuracy = accuracy_score(Y_train, Y_train_hat)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_hat)\n",
    "\n",
    "print()\n",
    "\n",
    "# print accuracies using accuracy score\n",
    "\n",
    "print(\"Using accuracy score:\")\n",
    "print()\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print()\n",
    "\n",
    "# print accuracies using evaluate\n",
    "\n",
    "train_loss, train_accuracy = TF_LSTM_RNN.evaluate(X_train_reshaped, Y_train)\n",
    "test_loss, test_accuracy = TF_LSTM_RNN.evaluate(X_test_reshaped, Y_test)\n",
    "\n",
    "print()\n",
    "print(\"Using evaluate:\")\n",
    "print()\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Training loss\", train_loss)\n",
    "print(\"Test loss\", test_loss)\n",
    "print()\n",
    "\n",
    "# confusion matrices\n",
    "\n",
    "print(\"Confusion matrix for train set:\\n\", confusion_matrix(Y_train, Y_train_hat))\n",
    "print()\n",
    "print(\"Confusion matrix for test set:\\n\", confusion_matrix(Y_test, Y_test_hat))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff78b29-d2b0-49d5-90d8-7d54291a0cda",
   "metadata": {},
   "source": [
    "## PyTorch Implementation - Don't grade this attempt, did it to learn something new and would love any feedback you may have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67df892-6004-48d1-989f-af8936221649",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Prepare the training, validation and test sets. 15 points\n",
    "- Use 50% data for training, 20% for validation, and 30% for testing\n",
    "- Set the batch size to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08816c41-87ee-427b-b3c1-182fa84a323b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "(25000, 256)\n",
      "(25000,)\n",
      "\n",
      "Validation set:\n",
      "(10000, 256)\n",
      "(10000,)\n",
      "\n",
      "Test set:\n",
      "(15000, 256)\n",
      "(15000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.5, random_state = 0)\n",
    "X_validation, X_test, Y_validation, Y_test = train_test_split(X_test, Y_test, test_size = 0.6, random_state = 0)\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print()\n",
    "print(\"Validation set:\")\n",
    "print(X_validation.shape)\n",
    "print(Y_validation.shape)\n",
    "print()\n",
    "print(\"Test set:\")\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print()\n",
    "\n",
    "# Use TensorDataset and DataLoader\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "Y_train_tensor = torch.tensor(Y_train)\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "\n",
    "X_validation_tensor = torch.tensor(X_validation)\n",
    "Y_validation_tensor = torch.tensor(Y_validation)\n",
    "validation_dataset = TensorDataset(X_validation_tensor, Y_validation_tensor)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "Y_test_tensor = torch.tensor(Y_test)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a7836-6816-4ef0-bfb6-e2a1a0fb3e0f",
   "metadata": {},
   "source": [
    "#### 4. Build a many-to-one RNN. 40 points\n",
    "- GRU or LSTM is preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ab9b5-307f-4997-b772-79d4c5ec2498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out, (hidden, cell) = self.lstm(X)\n",
    "        out = self.linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def train_model(self, train_dataloader, validation_dataloader, num_epochs, loss_kind, optimizer):\n",
    "        train_loss = []\n",
    "        validation_loss = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            epoch_train_losses = []\n",
    "            for inputs, labels in train_dataloader:\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs).squeeze()\n",
    "                tr_loss = loss_kind(outputs, labels)\n",
    "                tr_loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_train_losses.append(tr_loss.item())\n",
    "            \n",
    "            self.eval()\n",
    "            epoch_validation_losses = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validation_dataloader:\n",
    "                    inputs = inputs.float()\n",
    "                    labels = labels.float()\n",
    "                    outputs = self(inputs).squeeze()\n",
    "                    val_loss = loss_kind(outputs, labels)\n",
    "                    epoch_validation_losses.append(val_loss.item())\n",
    "               \n",
    "            avg_train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
    "            avg_validation_loss = sum(epoch_validation_losses) / len(epoch_validation_losses)\n",
    "            train_loss.append(avg_train_loss)\n",
    "            validation_loss.append(avg_validation_loss)\n",
    "            \n",
    "            print(\"Epoch: \", epoch + 1)\n",
    "            print(\"Training loss: \", tr_loss.item())\n",
    "            print(\"Validation loss: \", val_loss.item())\n",
    "            \n",
    "        return train_loss, validation_loss\n",
    "    \n",
    "    def evaluate(self, dataloader):\n",
    "        self.eval()\n",
    "        y_hat = []\n",
    "        y = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.float()\n",
    "                outputs = self(inputs).squeeze()\n",
    "                predictions = (outputs > 0.5).float()\n",
    "                y_hat.extend(predictions.numpy())\n",
    "                y.extend(labels.numpy())\n",
    "                \n",
    "        accuracy = accuracy_score(y, y_hat)\n",
    "        \n",
    "        return accuracy, y_hat, y\n",
    "\n",
    "# hyperparameters\n",
    "# - batch_size set above in previous cell\n",
    "\n",
    "input_size = 256\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "num_epochs = 500\n",
    "learning_rate = 0.005\n",
    "loss_kind = nn.BCELoss() # binary cross entropy\n",
    "\n",
    "Torch_LSTM_RNN = LSTM_Model(input_size, hidden_size, num_layers, output_size, batch_size)\n",
    "optimizer = Adam_torch(LSTM_RNN.parameters(), lr = learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b372815-e142-4cef-bfeb-031b63831cf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Train the above model. 30 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ff551-2317-4e82-ba96-0fe6e8457170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Training loss:  0.6865877509117126\n",
      "Validation loss:  0.6878781914710999\n",
      "Epoch:  2\n",
      "Training loss:  0.6954066157341003\n",
      "Validation loss:  0.693553626537323\n",
      "Epoch:  3\n",
      "Training loss:  0.6959971785545349\n",
      "Validation loss:  0.6900829076766968\n",
      "Epoch:  4\n",
      "Training loss:  0.6907013654708862\n",
      "Validation loss:  0.6936023235321045\n",
      "Epoch:  5\n",
      "Training loss:  0.71017986536026\n",
      "Validation loss:  0.6862073540687561\n",
      "Epoch:  6\n",
      "Training loss:  0.6894562840461731\n",
      "Validation loss:  0.6980143785476685\n",
      "Epoch:  7\n",
      "Training loss:  0.694052517414093\n",
      "Validation loss:  0.6907708048820496\n",
      "Epoch:  8\n",
      "Training loss:  0.6958293914794922\n",
      "Validation loss:  0.6962143182754517\n",
      "Epoch:  9\n",
      "Training loss:  0.6755180954933167\n",
      "Validation loss:  0.706966757774353\n",
      "Epoch:  10\n",
      "Training loss:  0.6835496425628662\n",
      "Validation loss:  0.6994297504425049\n",
      "Epoch:  11\n",
      "Training loss:  0.6891047358512878\n",
      "Validation loss:  0.702930212020874\n",
      "Epoch:  12\n",
      "Training loss:  0.7086129784584045\n",
      "Validation loss:  0.682745099067688\n",
      "Epoch:  13\n",
      "Training loss:  0.7016357183456421\n",
      "Validation loss:  0.7194178104400635\n",
      "Epoch:  14\n",
      "Training loss:  0.6943336725234985\n",
      "Validation loss:  0.7010229825973511\n",
      "Epoch:  15\n",
      "Training loss:  0.6662122011184692\n",
      "Validation loss:  0.6659269332885742\n",
      "Epoch:  16\n",
      "Training loss:  0.694955587387085\n",
      "Validation loss:  0.6832230091094971\n",
      "Epoch:  17\n",
      "Training loss:  0.6733330488204956\n",
      "Validation loss:  0.6665481328964233\n",
      "Epoch:  18\n",
      "Training loss:  0.6725621819496155\n",
      "Validation loss:  0.6899668574333191\n",
      "Epoch:  19\n",
      "Training loss:  0.6949625015258789\n",
      "Validation loss:  0.6974380016326904\n",
      "Epoch:  20\n",
      "Training loss:  0.6910439729690552\n",
      "Validation loss:  0.7012224197387695\n",
      "Epoch:  21\n",
      "Training loss:  0.6909158825874329\n",
      "Validation loss:  0.6866828799247742\n",
      "Epoch:  22\n",
      "Training loss:  0.6909521818161011\n",
      "Validation loss:  0.6999629735946655\n",
      "Epoch:  23\n",
      "Training loss:  0.6884240508079529\n",
      "Validation loss:  0.6985374093055725\n",
      "Epoch:  24\n",
      "Training loss:  0.6924154758453369\n",
      "Validation loss:  0.6940521001815796\n",
      "Epoch:  25\n",
      "Training loss:  0.6952709555625916\n",
      "Validation loss:  0.7281696796417236\n",
      "Epoch:  26\n",
      "Training loss:  0.6883586049079895\n",
      "Validation loss:  0.6954842805862427\n",
      "Epoch:  27\n",
      "Training loss:  0.6899644136428833\n",
      "Validation loss:  0.6781043410301208\n",
      "Epoch:  28\n",
      "Training loss:  0.6950365304946899\n",
      "Validation loss:  0.6630555987358093\n",
      "Epoch:  29\n",
      "Training loss:  0.6883175373077393\n",
      "Validation loss:  0.7081084847450256\n",
      "Epoch:  30\n",
      "Training loss:  0.6911948323249817\n",
      "Validation loss:  0.6782721281051636\n",
      "Epoch:  31\n",
      "Training loss:  0.6834806799888611\n",
      "Validation loss:  0.6873825192451477\n",
      "Epoch:  32\n",
      "Training loss:  0.6986652612686157\n",
      "Validation loss:  0.6740609407424927\n",
      "Epoch:  33\n",
      "Training loss:  0.7019038200378418\n",
      "Validation loss:  0.7076361179351807\n",
      "Epoch:  34\n",
      "Training loss:  0.7137173414230347\n",
      "Validation loss:  0.704334020614624\n",
      "Epoch:  35\n",
      "Training loss:  0.6896427869796753\n",
      "Validation loss:  0.6696237325668335\n",
      "Epoch:  36\n",
      "Training loss:  0.6786236763000488\n",
      "Validation loss:  0.6961221098899841\n",
      "Epoch:  37\n",
      "Training loss:  0.6717303991317749\n",
      "Validation loss:  0.711194634437561\n",
      "Epoch:  38\n",
      "Training loss:  0.6637576222419739\n",
      "Validation loss:  0.6763854622840881\n",
      "Epoch:  39\n",
      "Training loss:  0.6816109418869019\n",
      "Validation loss:  0.6936730146408081\n",
      "Epoch:  40\n",
      "Training loss:  0.6758860349655151\n",
      "Validation loss:  0.6878364682197571\n",
      "Epoch:  41\n",
      "Training loss:  0.6767936944961548\n",
      "Validation loss:  0.6940820217132568\n",
      "Epoch:  42\n",
      "Training loss:  0.6781663298606873\n",
      "Validation loss:  0.6740238070487976\n",
      "Epoch:  43\n",
      "Training loss:  0.6855329871177673\n",
      "Validation loss:  0.6631999015808105\n",
      "Epoch:  44\n",
      "Training loss:  0.680614173412323\n",
      "Validation loss:  0.709377646446228\n",
      "Epoch:  45\n",
      "Training loss:  0.6792446374893188\n",
      "Validation loss:  0.6958531737327576\n",
      "Epoch:  46\n",
      "Training loss:  0.6881645917892456\n",
      "Validation loss:  0.6917186975479126\n",
      "Epoch:  47\n",
      "Training loss:  0.6942480802536011\n",
      "Validation loss:  0.7036027908325195\n",
      "Epoch:  48\n",
      "Training loss:  0.6987022161483765\n",
      "Validation loss:  0.6998282670974731\n",
      "Epoch:  49\n",
      "Training loss:  0.6704109907150269\n",
      "Validation loss:  0.6978803277015686\n",
      "Epoch:  50\n",
      "Training loss:  0.6817426681518555\n",
      "Validation loss:  0.6919838786125183\n",
      "Epoch:  51\n",
      "Training loss:  0.696107029914856\n",
      "Validation loss:  0.688770592212677\n",
      "Epoch:  52\n",
      "Training loss:  0.6751309633255005\n",
      "Validation loss:  0.7096034288406372\n",
      "Epoch:  53\n",
      "Training loss:  0.6786422729492188\n",
      "Validation loss:  0.7565590143203735\n",
      "Epoch:  54\n",
      "Training loss:  0.6763720512390137\n",
      "Validation loss:  0.6784095764160156\n",
      "Epoch:  55\n",
      "Training loss:  0.6913307309150696\n",
      "Validation loss:  0.6845490336418152\n",
      "Epoch:  56\n",
      "Training loss:  0.6938343048095703\n",
      "Validation loss:  0.7753299474716187\n",
      "Epoch:  57\n",
      "Training loss:  0.6556762456893921\n",
      "Validation loss:  0.6756144762039185\n",
      "Epoch:  58\n",
      "Training loss:  0.6760095357894897\n",
      "Validation loss:  0.6808730959892273\n",
      "Epoch:  59\n",
      "Training loss:  0.6757415533065796\n",
      "Validation loss:  0.6611400842666626\n",
      "Epoch:  60\n",
      "Training loss:  0.696722149848938\n",
      "Validation loss:  0.7474119067192078\n",
      "Epoch:  61\n",
      "Training loss:  0.6861090660095215\n",
      "Validation loss:  0.6756842136383057\n",
      "Epoch:  62\n",
      "Training loss:  0.6979919672012329\n",
      "Validation loss:  0.7480217814445496\n",
      "Epoch:  63\n",
      "Training loss:  0.6750251054763794\n",
      "Validation loss:  0.6968215703964233\n",
      "Epoch:  64\n",
      "Training loss:  0.6835891604423523\n",
      "Validation loss:  0.7202498912811279\n",
      "Epoch:  65\n",
      "Training loss:  0.6260656118392944\n",
      "Validation loss:  0.7250166535377502\n",
      "Epoch:  66\n",
      "Training loss:  0.7116009593009949\n",
      "Validation loss:  0.7188277244567871\n",
      "Epoch:  67\n",
      "Training loss:  0.6710536479949951\n",
      "Validation loss:  0.6877751350402832\n",
      "Epoch:  68\n",
      "Training loss:  0.6687008142471313\n",
      "Validation loss:  0.696398913860321\n",
      "Epoch:  69\n",
      "Training loss:  0.6497048735618591\n",
      "Validation loss:  0.6950671076774597\n",
      "Epoch:  70\n",
      "Training loss:  0.6877322793006897\n",
      "Validation loss:  0.6606029272079468\n",
      "Epoch:  71\n",
      "Training loss:  0.7018535733222961\n",
      "Validation loss:  0.7221349477767944\n",
      "Epoch:  72\n",
      "Training loss:  0.6948348879814148\n",
      "Validation loss:  0.6895631551742554\n",
      "Epoch:  73\n",
      "Training loss:  0.6518863439559937\n",
      "Validation loss:  0.7367586493492126\n",
      "Epoch:  74\n",
      "Training loss:  0.6212344169616699\n",
      "Validation loss:  0.710010826587677\n",
      "Epoch:  75\n",
      "Training loss:  0.6848546266555786\n",
      "Validation loss:  0.642553448677063\n",
      "Epoch:  76\n",
      "Training loss:  0.6886574029922485\n",
      "Validation loss:  0.6470243334770203\n",
      "Epoch:  77\n",
      "Training loss:  0.71420818567276\n",
      "Validation loss:  0.708146870136261\n",
      "Epoch:  78\n",
      "Training loss:  0.6799926161766052\n",
      "Validation loss:  0.6349923014640808\n",
      "Epoch:  79\n",
      "Training loss:  0.7287943363189697\n",
      "Validation loss:  0.7054561376571655\n",
      "Epoch:  80\n",
      "Training loss:  0.6878978610038757\n",
      "Validation loss:  0.7426091432571411\n",
      "Epoch:  81\n",
      "Training loss:  0.648736834526062\n",
      "Validation loss:  0.711078405380249\n",
      "Epoch:  82\n",
      "Training loss:  0.6463218927383423\n",
      "Validation loss:  0.6745532751083374\n",
      "Epoch:  83\n",
      "Training loss:  0.6573922038078308\n",
      "Validation loss:  0.6927510499954224\n",
      "Epoch:  84\n",
      "Training loss:  0.6218560338020325\n",
      "Validation loss:  0.7101630568504333\n",
      "Epoch:  85\n",
      "Training loss:  0.7078293561935425\n",
      "Validation loss:  0.6610320210456848\n",
      "Epoch:  86\n",
      "Training loss:  0.6721181273460388\n",
      "Validation loss:  0.68498694896698\n",
      "Epoch:  87\n",
      "Training loss:  0.6891036033630371\n",
      "Validation loss:  0.6748951077461243\n",
      "Epoch:  88\n",
      "Training loss:  0.6933323740959167\n",
      "Validation loss:  0.6984789967536926\n",
      "Epoch:  89\n",
      "Training loss:  0.6974543333053589\n",
      "Validation loss:  0.6744480133056641\n",
      "Epoch:  90\n",
      "Training loss:  0.6563948392868042\n",
      "Validation loss:  0.6622607707977295\n",
      "Epoch:  91\n",
      "Training loss:  0.6844367980957031\n",
      "Validation loss:  0.6851237416267395\n",
      "Epoch:  92\n",
      "Training loss:  0.6875308752059937\n",
      "Validation loss:  0.7161445617675781\n",
      "Epoch:  93\n",
      "Training loss:  0.6438606977462769\n",
      "Validation loss:  0.6970965266227722\n",
      "Epoch:  94\n",
      "Training loss:  0.674500584602356\n",
      "Validation loss:  0.7884960770606995\n",
      "Epoch:  95\n",
      "Training loss:  0.7125064134597778\n",
      "Validation loss:  0.6849347949028015\n",
      "Epoch:  96\n",
      "Training loss:  0.6960210800170898\n",
      "Validation loss:  0.6575035452842712\n",
      "Epoch:  97\n",
      "Training loss:  0.6938508749008179\n",
      "Validation loss:  0.6594054698944092\n",
      "Epoch:  98\n",
      "Training loss:  0.6726592183113098\n",
      "Validation loss:  0.6886619925498962\n",
      "Epoch:  99\n",
      "Training loss:  0.6777297854423523\n",
      "Validation loss:  0.784936785697937\n",
      "Epoch:  100\n",
      "Training loss:  0.677260160446167\n",
      "Validation loss:  0.7336346507072449\n",
      "Epoch:  101\n",
      "Training loss:  0.6780821084976196\n",
      "Validation loss:  0.7052079439163208\n",
      "Epoch:  102\n",
      "Training loss:  0.676892876625061\n",
      "Validation loss:  0.6813209056854248\n",
      "Epoch:  103\n",
      "Training loss:  0.6864473223686218\n",
      "Validation loss:  0.7410213947296143\n",
      "Epoch:  104\n",
      "Training loss:  0.6383715867996216\n",
      "Validation loss:  0.7312596440315247\n",
      "Epoch:  105\n",
      "Training loss:  0.6737712621688843\n",
      "Validation loss:  0.7087079882621765\n",
      "Epoch:  106\n",
      "Training loss:  0.6636303663253784\n",
      "Validation loss:  0.658259928226471\n",
      "Epoch:  107\n",
      "Training loss:  0.6483897566795349\n",
      "Validation loss:  0.6866804957389832\n",
      "Epoch:  108\n",
      "Training loss:  0.6911499500274658\n",
      "Validation loss:  0.731215238571167\n",
      "Epoch:  109\n",
      "Training loss:  0.6874390840530396\n",
      "Validation loss:  0.7521443963050842\n",
      "Epoch:  110\n",
      "Training loss:  0.6791300773620605\n",
      "Validation loss:  0.7464972138404846\n",
      "Epoch:  111\n",
      "Training loss:  0.6516371369361877\n",
      "Validation loss:  0.7029300928115845\n",
      "Epoch:  112\n",
      "Training loss:  0.667601466178894\n",
      "Validation loss:  0.6789475083351135\n",
      "Epoch:  113\n",
      "Training loss:  0.665615439414978\n",
      "Validation loss:  0.6701701283454895\n",
      "Epoch:  114\n",
      "Training loss:  0.7088539600372314\n",
      "Validation loss:  0.6894670724868774\n",
      "Epoch:  115\n",
      "Training loss:  0.6767066121101379\n",
      "Validation loss:  0.671290397644043\n",
      "Epoch:  116\n",
      "Training loss:  0.6884697079658508\n",
      "Validation loss:  0.6765118837356567\n",
      "Epoch:  117\n",
      "Training loss:  0.6992416381835938\n",
      "Validation loss:  0.7602778673171997\n",
      "Epoch:  118\n",
      "Training loss:  0.6342294216156006\n",
      "Validation loss:  0.6956206560134888\n",
      "Epoch:  119\n",
      "Training loss:  0.6824284791946411\n",
      "Validation loss:  0.6968203783035278\n",
      "Epoch:  120\n",
      "Training loss:  0.6357780694961548\n",
      "Validation loss:  0.692548930644989\n",
      "Epoch:  121\n",
      "Training loss:  0.6813609600067139\n",
      "Validation loss:  0.7194637060165405\n",
      "Epoch:  122\n",
      "Training loss:  0.698822557926178\n",
      "Validation loss:  0.6347604990005493\n",
      "Epoch:  123\n",
      "Training loss:  0.6699613928794861\n",
      "Validation loss:  0.6787897348403931\n",
      "Epoch:  124\n",
      "Training loss:  0.6897822618484497\n",
      "Validation loss:  0.7952343821525574\n",
      "Epoch:  125\n",
      "Training loss:  0.7081124186515808\n",
      "Validation loss:  0.6586189866065979\n",
      "Epoch:  126\n",
      "Training loss:  0.7027696371078491\n",
      "Validation loss:  0.6707930564880371\n",
      "Epoch:  127\n",
      "Training loss:  0.6719223260879517\n",
      "Validation loss:  0.7217162847518921\n",
      "Epoch:  128\n",
      "Training loss:  0.7014070749282837\n",
      "Validation loss:  0.6805471181869507\n",
      "Epoch:  129\n",
      "Training loss:  0.6726834177970886\n",
      "Validation loss:  1.1664339303970337\n",
      "Epoch:  130\n",
      "Training loss:  0.6753257513046265\n",
      "Validation loss:  0.7079757452011108\n",
      "Epoch:  131\n",
      "Training loss:  0.6362797617912292\n",
      "Validation loss:  0.9014434814453125\n",
      "Epoch:  132\n",
      "Training loss:  0.7056477665901184\n",
      "Validation loss:  0.699938178062439\n",
      "Epoch:  133\n",
      "Training loss:  0.6738722920417786\n",
      "Validation loss:  0.8780861496925354\n",
      "Epoch:  134\n",
      "Training loss:  0.6907052993774414\n",
      "Validation loss:  0.7087348699569702\n",
      "Epoch:  135\n",
      "Training loss:  0.6612184047698975\n",
      "Validation loss:  0.692528247833252\n",
      "Epoch:  136\n",
      "Training loss:  0.7034092545509338\n",
      "Validation loss:  0.8333749771118164\n",
      "Epoch:  137\n",
      "Training loss:  0.6645936369895935\n",
      "Validation loss:  0.6096742153167725\n",
      "Epoch:  138\n",
      "Training loss:  0.6854360699653625\n",
      "Validation loss:  0.6681588292121887\n",
      "Epoch:  139\n",
      "Training loss:  0.6499625444412231\n",
      "Validation loss:  0.7457154989242554\n",
      "Epoch:  140\n",
      "Training loss:  0.6859604120254517\n",
      "Validation loss:  0.8160216212272644\n",
      "Epoch:  141\n",
      "Training loss:  0.6812105774879456\n",
      "Validation loss:  0.6808516979217529\n",
      "Epoch:  142\n",
      "Training loss:  0.6688237190246582\n",
      "Validation loss:  0.6356045007705688\n",
      "Epoch:  143\n",
      "Training loss:  0.6424378156661987\n",
      "Validation loss:  0.6824898719787598\n",
      "Epoch:  144\n",
      "Training loss:  0.6648676991462708\n",
      "Validation loss:  0.7115539908409119\n",
      "Epoch:  145\n",
      "Training loss:  0.6807466745376587\n",
      "Validation loss:  0.7667356133460999\n",
      "Epoch:  146\n",
      "Training loss:  0.6541226506233215\n",
      "Validation loss:  0.7301125526428223\n",
      "Epoch:  147\n",
      "Training loss:  0.6751047968864441\n",
      "Validation loss:  0.6549487113952637\n",
      "Epoch:  148\n",
      "Training loss:  0.6752812266349792\n",
      "Validation loss:  0.9440324306488037\n",
      "Epoch:  149\n",
      "Training loss:  0.6810084581375122\n",
      "Validation loss:  0.747338056564331\n",
      "Epoch:  150\n",
      "Training loss:  0.6639961004257202\n",
      "Validation loss:  0.9357419013977051\n",
      "Epoch:  151\n",
      "Training loss:  0.6365052461624146\n",
      "Validation loss:  0.6549084186553955\n",
      "Epoch:  152\n",
      "Training loss:  0.6632703542709351\n",
      "Validation loss:  0.6631457805633545\n",
      "Epoch:  153\n",
      "Training loss:  0.6910369992256165\n",
      "Validation loss:  0.7700934410095215\n",
      "Epoch:  154\n",
      "Training loss:  0.6499619483947754\n",
      "Validation loss:  0.9801201820373535\n",
      "Epoch:  155\n",
      "Training loss:  0.68748539686203\n",
      "Validation loss:  0.7495404481887817\n",
      "Epoch:  156\n",
      "Training loss:  0.7446004152297974\n",
      "Validation loss:  0.6618757843971252\n",
      "Epoch:  157\n",
      "Training loss:  0.6519293785095215\n",
      "Validation loss:  0.7208617329597473\n",
      "Epoch:  158\n",
      "Training loss:  0.676885724067688\n",
      "Validation loss:  0.7412814497947693\n",
      "Epoch:  159\n",
      "Training loss:  0.6820991635322571\n",
      "Validation loss:  0.6818674206733704\n",
      "Epoch:  160\n",
      "Training loss:  0.6520093083381653\n",
      "Validation loss:  0.8187383413314819\n",
      "Epoch:  161\n",
      "Training loss:  0.6204332113265991\n",
      "Validation loss:  0.6721203327178955\n",
      "Epoch:  162\n",
      "Training loss:  0.6717081069946289\n",
      "Validation loss:  0.923297643661499\n",
      "Epoch:  163\n",
      "Training loss:  0.6420367360115051\n",
      "Validation loss:  0.680595874786377\n",
      "Epoch:  164\n",
      "Training loss:  0.6337282657623291\n",
      "Validation loss:  0.7541816234588623\n",
      "Epoch:  165\n",
      "Training loss:  0.6647547483444214\n",
      "Validation loss:  0.6690623164176941\n",
      "Epoch:  166\n",
      "Training loss:  0.6562038064002991\n",
      "Validation loss:  0.8028697967529297\n",
      "Epoch:  167\n",
      "Training loss:  0.66290283203125\n",
      "Validation loss:  0.7940734028816223\n",
      "Epoch:  168\n",
      "Training loss:  0.7193425893783569\n",
      "Validation loss:  0.7078295350074768\n",
      "Epoch:  169\n",
      "Training loss:  0.6659854054450989\n",
      "Validation loss:  0.6915152072906494\n",
      "Epoch:  170\n",
      "Training loss:  0.6958049535751343\n",
      "Validation loss:  0.5604677796363831\n",
      "Epoch:  171\n",
      "Training loss:  0.6983010768890381\n",
      "Validation loss:  0.7131540179252625\n",
      "Epoch:  172\n",
      "Training loss:  0.6492099165916443\n",
      "Validation loss:  0.6756798028945923\n",
      "Epoch:  173\n",
      "Training loss:  0.6660552620887756\n",
      "Validation loss:  0.6530383229255676\n",
      "Epoch:  174\n",
      "Training loss:  0.6980959177017212\n",
      "Validation loss:  1.0929511785507202\n",
      "Epoch:  175\n",
      "Training loss:  0.6741427779197693\n",
      "Validation loss:  0.64491206407547\n",
      "Epoch:  176\n",
      "Training loss:  0.72022545337677\n",
      "Validation loss:  0.7060270309448242\n",
      "Epoch:  177\n",
      "Training loss:  0.6698130369186401\n",
      "Validation loss:  0.8297008872032166\n",
      "Epoch:  178\n",
      "Training loss:  0.6705163717269897\n",
      "Validation loss:  0.6955324411392212\n",
      "Epoch:  179\n",
      "Training loss:  0.6752992868423462\n",
      "Validation loss:  0.6450898051261902\n",
      "Epoch:  180\n",
      "Training loss:  0.6835982799530029\n",
      "Validation loss:  0.7158628106117249\n",
      "Epoch:  181\n",
      "Training loss:  0.6287437677383423\n",
      "Validation loss:  0.6886157989501953\n",
      "Epoch:  182\n",
      "Training loss:  0.6585475206375122\n",
      "Validation loss:  0.6356621384620667\n",
      "Epoch:  183\n",
      "Training loss:  0.6704900860786438\n",
      "Validation loss:  0.7840318083763123\n",
      "Epoch:  184\n",
      "Training loss:  0.6809731721878052\n",
      "Validation loss:  0.757231593132019\n",
      "Epoch:  185\n",
      "Training loss:  0.6802685260772705\n",
      "Validation loss:  0.8143816590309143\n",
      "Epoch:  186\n",
      "Training loss:  0.694266140460968\n",
      "Validation loss:  0.7145878076553345\n",
      "Epoch:  187\n",
      "Training loss:  0.6740831136703491\n",
      "Validation loss:  0.7195836305618286\n",
      "Epoch:  188\n",
      "Training loss:  0.6402462124824524\n",
      "Validation loss:  0.8271604180335999\n",
      "Epoch:  189\n",
      "Training loss:  0.6860889196395874\n",
      "Validation loss:  0.6645545959472656\n",
      "Epoch:  190\n",
      "Training loss:  0.6742990612983704\n",
      "Validation loss:  0.5935971140861511\n",
      "Epoch:  191\n",
      "Training loss:  0.6734734177589417\n",
      "Validation loss:  0.6950221061706543\n",
      "Epoch:  192\n",
      "Training loss:  0.7234429121017456\n",
      "Validation loss:  0.7165398597717285\n",
      "Epoch:  193\n",
      "Training loss:  0.6600160002708435\n",
      "Validation loss:  0.671932578086853\n",
      "Epoch:  194\n",
      "Training loss:  0.6636629104614258\n",
      "Validation loss:  0.6703785061836243\n",
      "Epoch:  195\n",
      "Training loss:  0.6515201330184937\n",
      "Validation loss:  0.7008730173110962\n",
      "Epoch:  196\n",
      "Training loss:  0.6883344650268555\n",
      "Validation loss:  0.6882327198982239\n",
      "Epoch:  197\n",
      "Training loss:  0.6696252226829529\n",
      "Validation loss:  0.6627364158630371\n",
      "Epoch:  198\n",
      "Training loss:  0.6649456024169922\n",
      "Validation loss:  0.7720499038696289\n",
      "Epoch:  199\n",
      "Training loss:  0.6714794039726257\n",
      "Validation loss:  0.7933343052864075\n",
      "Epoch:  200\n",
      "Training loss:  0.7026578783988953\n",
      "Validation loss:  0.6270235180854797\n",
      "Epoch:  201\n",
      "Training loss:  0.6545500159263611\n",
      "Validation loss:  0.7752586007118225\n",
      "Epoch:  202\n",
      "Training loss:  0.6953890919685364\n",
      "Validation loss:  0.684278666973114\n",
      "Epoch:  203\n",
      "Training loss:  0.6765058636665344\n",
      "Validation loss:  0.7151917219161987\n",
      "Epoch:  204\n",
      "Training loss:  0.6603772640228271\n",
      "Validation loss:  0.7456108331680298\n",
      "Epoch:  205\n",
      "Training loss:  0.6784592866897583\n",
      "Validation loss:  0.837478756904602\n",
      "Epoch:  206\n",
      "Training loss:  0.68150794506073\n",
      "Validation loss:  0.7343892455101013\n",
      "Epoch:  207\n",
      "Training loss:  0.6956110000610352\n",
      "Validation loss:  0.6923307180404663\n",
      "Epoch:  208\n",
      "Training loss:  0.6958094835281372\n",
      "Validation loss:  0.63492351770401\n",
      "Epoch:  209\n",
      "Training loss:  0.6470831036567688\n",
      "Validation loss:  0.6839979290962219\n",
      "Epoch:  210\n",
      "Training loss:  0.6765040159225464\n",
      "Validation loss:  0.6543832421302795\n",
      "Epoch:  211\n",
      "Training loss:  0.6425018906593323\n",
      "Validation loss:  0.7773847579956055\n",
      "Epoch:  212\n",
      "Training loss:  0.6850184202194214\n",
      "Validation loss:  0.8455986976623535\n",
      "Epoch:  213\n",
      "Training loss:  0.6949627995491028\n",
      "Validation loss:  1.1223629713058472\n",
      "Epoch:  214\n",
      "Training loss:  0.6134097576141357\n",
      "Validation loss:  0.6994090676307678\n",
      "Epoch:  215\n",
      "Training loss:  0.6632694005966187\n",
      "Validation loss:  0.7013164758682251\n",
      "Epoch:  216\n",
      "Training loss:  0.6906083822250366\n",
      "Validation loss:  0.6383959650993347\n",
      "Epoch:  217\n",
      "Training loss:  0.6646420359611511\n",
      "Validation loss:  0.7929375767707825\n",
      "Epoch:  218\n",
      "Training loss:  0.7105647921562195\n",
      "Validation loss:  0.6347829103469849\n",
      "Epoch:  219\n",
      "Training loss:  0.6433956027030945\n",
      "Validation loss:  0.7065850496292114\n",
      "Epoch:  220\n",
      "Training loss:  0.691043496131897\n",
      "Validation loss:  0.7596108913421631\n",
      "Epoch:  221\n",
      "Training loss:  0.6064506769180298\n",
      "Validation loss:  1.006568193435669\n",
      "Epoch:  222\n",
      "Training loss:  0.6014825105667114\n",
      "Validation loss:  0.6884722709655762\n",
      "Epoch:  223\n",
      "Training loss:  0.6487718820571899\n",
      "Validation loss:  0.6367635726928711\n",
      "Epoch:  224\n",
      "Training loss:  0.6629946827888489\n",
      "Validation loss:  0.7312589883804321\n",
      "Epoch:  225\n",
      "Training loss:  0.6604480743408203\n",
      "Validation loss:  0.672918438911438\n",
      "Epoch:  226\n",
      "Training loss:  0.6635274887084961\n",
      "Validation loss:  0.6669507026672363\n",
      "Epoch:  227\n",
      "Training loss:  0.6286697387695312\n",
      "Validation loss:  0.7292031049728394\n",
      "Epoch:  228\n",
      "Training loss:  0.666479229927063\n",
      "Validation loss:  0.6679850816726685\n",
      "Epoch:  229\n",
      "Training loss:  0.6999033689498901\n",
      "Validation loss:  0.7323874235153198\n",
      "Epoch:  230\n",
      "Training loss:  0.6996151804924011\n",
      "Validation loss:  0.7574260830879211\n",
      "Epoch:  231\n",
      "Training loss:  0.6739236116409302\n",
      "Validation loss:  0.8398734927177429\n",
      "Epoch:  232\n",
      "Training loss:  0.6634618639945984\n",
      "Validation loss:  0.7848362326622009\n",
      "Epoch:  233\n",
      "Training loss:  0.6851969957351685\n",
      "Validation loss:  0.933417558670044\n",
      "Epoch:  234\n",
      "Training loss:  0.6773794293403625\n",
      "Validation loss:  0.6561866402626038\n",
      "Epoch:  235\n",
      "Training loss:  0.636938214302063\n",
      "Validation loss:  0.667568564414978\n",
      "Epoch:  236\n",
      "Training loss:  0.6695080995559692\n",
      "Validation loss:  0.7086350917816162\n",
      "Epoch:  237\n",
      "Training loss:  0.6991086006164551\n",
      "Validation loss:  0.6868109703063965\n",
      "Epoch:  238\n",
      "Training loss:  0.6723214387893677\n",
      "Validation loss:  0.7036923170089722\n",
      "Epoch:  239\n",
      "Training loss:  0.6076429486274719\n",
      "Validation loss:  1.099991798400879\n",
      "Epoch:  240\n",
      "Training loss:  0.663909912109375\n",
      "Validation loss:  0.6722211241722107\n",
      "Epoch:  241\n",
      "Training loss:  0.6688492298126221\n",
      "Validation loss:  0.7489317655563354\n",
      "Epoch:  242\n",
      "Training loss:  0.6300077438354492\n",
      "Validation loss:  0.6640561819076538\n",
      "Epoch:  243\n",
      "Training loss:  0.657410740852356\n",
      "Validation loss:  2.0274124145507812\n",
      "Epoch:  244\n",
      "Training loss:  0.7113708853721619\n",
      "Validation loss:  0.6519564390182495\n",
      "Epoch:  245\n",
      "Training loss:  0.6987334489822388\n",
      "Validation loss:  0.7030413150787354\n",
      "Epoch:  246\n",
      "Training loss:  0.6251235604286194\n",
      "Validation loss:  0.7046754360198975\n",
      "Epoch:  247\n",
      "Training loss:  0.6627135276794434\n",
      "Validation loss:  0.6548146605491638\n",
      "Epoch:  248\n",
      "Training loss:  0.6400578022003174\n",
      "Validation loss:  0.6648119688034058\n",
      "Epoch:  249\n",
      "Training loss:  0.6834484934806824\n",
      "Validation loss:  0.7068912982940674\n",
      "Epoch:  250\n",
      "Training loss:  0.6419121623039246\n",
      "Validation loss:  0.7117888331413269\n",
      "Epoch:  251\n",
      "Training loss:  0.6736832857131958\n",
      "Validation loss:  0.7687666416168213\n",
      "Epoch:  252\n",
      "Training loss:  0.6985491514205933\n",
      "Validation loss:  0.6772316098213196\n",
      "Epoch:  253\n",
      "Training loss:  0.6444852352142334\n",
      "Validation loss:  0.6383395195007324\n",
      "Epoch:  254\n",
      "Training loss:  0.6756661534309387\n",
      "Validation loss:  0.7557662129402161\n",
      "Epoch:  255\n",
      "Training loss:  0.675493597984314\n",
      "Validation loss:  0.6392205953598022\n",
      "Epoch:  256\n",
      "Training loss:  0.6539859771728516\n",
      "Validation loss:  0.65864098072052\n",
      "Epoch:  257\n",
      "Training loss:  0.7447996735572815\n",
      "Validation loss:  0.6438243985176086\n",
      "Epoch:  258\n",
      "Training loss:  0.6554340124130249\n",
      "Validation loss:  0.6885986924171448\n",
      "Epoch:  259\n",
      "Training loss:  0.6430341601371765\n",
      "Validation loss:  0.7261661887168884\n",
      "Epoch:  260\n",
      "Training loss:  0.6595429182052612\n",
      "Validation loss:  0.8683765530586243\n",
      "Epoch:  261\n",
      "Training loss:  0.6239115595817566\n",
      "Validation loss:  0.5962311625480652\n",
      "Epoch:  262\n",
      "Training loss:  0.6190981268882751\n",
      "Validation loss:  1.1143975257873535\n",
      "Epoch:  263\n",
      "Training loss:  0.672545313835144\n",
      "Validation loss:  0.8395727872848511\n",
      "Epoch:  264\n",
      "Training loss:  0.629092276096344\n",
      "Validation loss:  0.7027531266212463\n",
      "Epoch:  265\n",
      "Training loss:  0.69996577501297\n",
      "Validation loss:  0.6832069754600525\n",
      "Epoch:  266\n",
      "Training loss:  0.6523921489715576\n",
      "Validation loss:  0.66466224193573\n",
      "Epoch:  267\n",
      "Training loss:  0.6133038401603699\n",
      "Validation loss:  0.7153497934341431\n",
      "Epoch:  268\n",
      "Training loss:  0.6117995977401733\n",
      "Validation loss:  0.6937699317932129\n",
      "Epoch:  269\n",
      "Training loss:  0.6481625437736511\n",
      "Validation loss:  0.7592334151268005\n",
      "Epoch:  270\n",
      "Training loss:  0.6563959121704102\n",
      "Validation loss:  0.8138203620910645\n",
      "Epoch:  271\n",
      "Training loss:  0.7141210436820984\n",
      "Validation loss:  0.6629825830459595\n",
      "Epoch:  272\n",
      "Training loss:  0.6897244453430176\n",
      "Validation loss:  0.842799961566925\n",
      "Epoch:  273\n",
      "Training loss:  0.6771904826164246\n",
      "Validation loss:  0.6827393770217896\n",
      "Epoch:  274\n",
      "Training loss:  0.6670486330986023\n",
      "Validation loss:  0.6399436593055725\n",
      "Epoch:  275\n",
      "Training loss:  0.6059519648551941\n",
      "Validation loss:  0.7111642360687256\n",
      "Epoch:  276\n",
      "Training loss:  0.6260476112365723\n",
      "Validation loss:  1.1014586687088013\n",
      "Epoch:  277\n",
      "Training loss:  0.5933553576469421\n",
      "Validation loss:  0.6835184097290039\n",
      "Epoch:  278\n",
      "Training loss:  0.6849228739738464\n",
      "Validation loss:  0.6664965152740479\n",
      "Epoch:  279\n",
      "Training loss:  0.6361063122749329\n",
      "Validation loss:  0.7002660036087036\n",
      "Epoch:  280\n",
      "Training loss:  0.6630403399467468\n",
      "Validation loss:  0.671042263507843\n",
      "Epoch:  281\n",
      "Training loss:  0.6883782148361206\n",
      "Validation loss:  0.7119548320770264\n",
      "Epoch:  282\n",
      "Training loss:  0.6273034811019897\n",
      "Validation loss:  0.6761600971221924\n",
      "Epoch:  283\n",
      "Training loss:  0.6808781623840332\n",
      "Validation loss:  0.688880205154419\n",
      "Epoch:  284\n",
      "Training loss:  0.6536380052566528\n",
      "Validation loss:  0.7118536829948425\n",
      "Epoch:  285\n",
      "Training loss:  0.663664698600769\n",
      "Validation loss:  0.6777679920196533\n",
      "Epoch:  286\n",
      "Training loss:  0.6379967927932739\n",
      "Validation loss:  0.7022318840026855\n",
      "Epoch:  287\n",
      "Training loss:  0.6931350827217102\n",
      "Validation loss:  0.6966686248779297\n",
      "Epoch:  288\n",
      "Training loss:  0.6704584360122681\n",
      "Validation loss:  0.7001513242721558\n",
      "Epoch:  289\n",
      "Training loss:  0.6869207620620728\n",
      "Validation loss:  0.7124900221824646\n",
      "Epoch:  290\n",
      "Training loss:  0.6082102060317993\n",
      "Validation loss:  0.8728116750717163\n",
      "Epoch:  291\n",
      "Training loss:  0.6832669973373413\n",
      "Validation loss:  0.6838274598121643\n",
      "Epoch:  292\n",
      "Training loss:  0.6547137498855591\n",
      "Validation loss:  0.7464793920516968\n",
      "Epoch:  293\n",
      "Training loss:  0.6609300374984741\n",
      "Validation loss:  0.6989808082580566\n",
      "Epoch:  294\n",
      "Training loss:  0.6476250886917114\n",
      "Validation loss:  1.4909907579421997\n",
      "Epoch:  295\n",
      "Training loss:  0.7435553669929504\n",
      "Validation loss:  0.6783807277679443\n",
      "Epoch:  296\n",
      "Training loss:  0.7256746292114258\n",
      "Validation loss:  0.7522523403167725\n",
      "Epoch:  297\n",
      "Training loss:  0.6697989106178284\n",
      "Validation loss:  0.6886374354362488\n",
      "Epoch:  298\n",
      "Training loss:  0.6257113218307495\n",
      "Validation loss:  0.7354838848114014\n",
      "Epoch:  299\n",
      "Training loss:  0.7279002666473389\n",
      "Validation loss:  0.7426180243492126\n",
      "Epoch:  300\n",
      "Training loss:  0.6372197866439819\n",
      "Validation loss:  0.7072106003761292\n",
      "Epoch:  301\n",
      "Training loss:  0.6646295189857483\n",
      "Validation loss:  0.7002151012420654\n",
      "Epoch:  302\n",
      "Training loss:  0.6376839876174927\n",
      "Validation loss:  0.8872076869010925\n",
      "Epoch:  303\n",
      "Training loss:  0.7196097373962402\n",
      "Validation loss:  0.6447896361351013\n",
      "Epoch:  304\n",
      "Training loss:  0.6586173176765442\n",
      "Validation loss:  0.8710559010505676\n",
      "Epoch:  305\n",
      "Training loss:  0.6462414264678955\n",
      "Validation loss:  0.6891024112701416\n",
      "Epoch:  306\n",
      "Training loss:  0.6602257490158081\n",
      "Validation loss:  0.901566207408905\n",
      "Epoch:  307\n",
      "Training loss:  0.6167629361152649\n",
      "Validation loss:  0.6831568479537964\n",
      "Epoch:  308\n",
      "Training loss:  0.6834301948547363\n",
      "Validation loss:  0.6398261785507202\n",
      "Epoch:  309\n",
      "Training loss:  0.6434427499771118\n",
      "Validation loss:  0.6723098754882812\n",
      "Epoch:  310\n",
      "Training loss:  0.6691609621047974\n",
      "Validation loss:  0.7865893244743347\n",
      "Epoch:  311\n",
      "Training loss:  0.700274646282196\n",
      "Validation loss:  0.7101395726203918\n",
      "Epoch:  312\n",
      "Training loss:  0.6793877482414246\n",
      "Validation loss:  0.8300821781158447\n",
      "Epoch:  313\n",
      "Training loss:  0.6019977331161499\n",
      "Validation loss:  0.65395587682724\n",
      "Epoch:  314\n",
      "Training loss:  0.6807749271392822\n",
      "Validation loss:  0.8142837285995483\n",
      "Epoch:  315\n",
      "Training loss:  0.7340067625045776\n",
      "Validation loss:  0.6467205286026001\n",
      "Epoch:  316\n",
      "Training loss:  0.6340739727020264\n",
      "Validation loss:  0.7399064898490906\n",
      "Epoch:  317\n",
      "Training loss:  0.6610556244850159\n",
      "Validation loss:  0.7164862155914307\n",
      "Epoch:  318\n",
      "Training loss:  0.6903436183929443\n",
      "Validation loss:  0.6810414791107178\n",
      "Epoch:  319\n",
      "Training loss:  0.6524559259414673\n",
      "Validation loss:  0.6698740124702454\n",
      "Epoch:  320\n",
      "Training loss:  0.6995348930358887\n",
      "Validation loss:  0.7012079358100891\n",
      "Epoch:  321\n",
      "Training loss:  0.6481088399887085\n",
      "Validation loss:  0.6920108795166016\n",
      "Epoch:  322\n",
      "Training loss:  0.7100635170936584\n",
      "Validation loss:  0.7801387906074524\n",
      "Epoch:  323\n",
      "Training loss:  0.6654308438301086\n",
      "Validation loss:  0.7080221176147461\n",
      "Epoch:  324\n",
      "Training loss:  0.641921877861023\n",
      "Validation loss:  0.8522395491600037\n",
      "Epoch:  325\n",
      "Training loss:  0.6923578977584839\n",
      "Validation loss:  0.6969228982925415\n",
      "Epoch:  326\n",
      "Training loss:  0.6149095296859741\n",
      "Validation loss:  0.6887927055358887\n",
      "Epoch:  327\n",
      "Training loss:  0.6747921109199524\n",
      "Validation loss:  0.7359133958816528\n",
      "Epoch:  328\n",
      "Training loss:  0.6581954956054688\n",
      "Validation loss:  0.5865658521652222\n",
      "Epoch:  329\n",
      "Training loss:  0.6427205801010132\n",
      "Validation loss:  0.7086164951324463\n",
      "Epoch:  330\n",
      "Training loss:  0.6627241373062134\n",
      "Validation loss:  0.6429580450057983\n",
      "Epoch:  331\n",
      "Training loss:  0.6362961530685425\n",
      "Validation loss:  0.7957596182823181\n",
      "Epoch:  332\n",
      "Training loss:  0.6738165616989136\n",
      "Validation loss:  0.6872568130493164\n",
      "Epoch:  333\n",
      "Training loss:  0.6722434163093567\n",
      "Validation loss:  0.7986133098602295\n",
      "Epoch:  334\n",
      "Training loss:  0.731618344783783\n",
      "Validation loss:  0.6528559327125549\n",
      "Epoch:  335\n",
      "Training loss:  0.6107131838798523\n",
      "Validation loss:  0.6597164273262024\n",
      "Epoch:  336\n",
      "Training loss:  0.695324182510376\n",
      "Validation loss:  0.6898669600486755\n",
      "Epoch:  337\n",
      "Training loss:  0.7000812292098999\n",
      "Validation loss:  0.6498243808746338\n",
      "Epoch:  338\n",
      "Training loss:  0.6324871778488159\n",
      "Validation loss:  1.1508972644805908\n",
      "Epoch:  339\n",
      "Training loss:  0.7136962413787842\n",
      "Validation loss:  0.5952839851379395\n",
      "Epoch:  340\n",
      "Training loss:  0.6640026569366455\n",
      "Validation loss:  0.8856775760650635\n",
      "Epoch:  341\n",
      "Training loss:  0.6261755228042603\n",
      "Validation loss:  0.7177582383155823\n",
      "Epoch:  342\n",
      "Training loss:  0.7056059241294861\n",
      "Validation loss:  0.6906260848045349\n",
      "Epoch:  343\n",
      "Training loss:  0.6628672480583191\n",
      "Validation loss:  0.6578543186187744\n",
      "Epoch:  344\n",
      "Training loss:  0.6612123250961304\n",
      "Validation loss:  0.6948305368423462\n",
      "Epoch:  345\n",
      "Training loss:  0.6632811427116394\n",
      "Validation loss:  0.699264645576477\n",
      "Epoch:  346\n",
      "Training loss:  0.6482154726982117\n",
      "Validation loss:  1.5593538284301758\n",
      "Epoch:  347\n",
      "Training loss:  0.632573127746582\n",
      "Validation loss:  0.6794909238815308\n",
      "Epoch:  348\n",
      "Training loss:  0.6692174077033997\n",
      "Validation loss:  0.6627795100212097\n",
      "Epoch:  349\n",
      "Training loss:  0.6429030299186707\n",
      "Validation loss:  0.6643044352531433\n",
      "Epoch:  350\n",
      "Training loss:  0.7042635083198547\n",
      "Validation loss:  0.7747523784637451\n",
      "Epoch:  351\n",
      "Training loss:  0.7319915294647217\n",
      "Validation loss:  0.7655971646308899\n",
      "Epoch:  352\n",
      "Training loss:  0.674836277961731\n",
      "Validation loss:  0.8606535792350769\n",
      "Epoch:  353\n",
      "Training loss:  0.6491863131523132\n",
      "Validation loss:  0.7292315363883972\n",
      "Epoch:  354\n",
      "Training loss:  0.6799830794334412\n",
      "Validation loss:  0.6732864379882812\n",
      "Epoch:  355\n",
      "Training loss:  0.698848307132721\n",
      "Validation loss:  0.7185587882995605\n",
      "Epoch:  356\n",
      "Training loss:  0.6401470303535461\n",
      "Validation loss:  0.8011361956596375\n",
      "Epoch:  357\n",
      "Training loss:  0.6812272071838379\n",
      "Validation loss:  0.729157567024231\n",
      "Epoch:  358\n",
      "Training loss:  0.6763601303100586\n",
      "Validation loss:  0.7096195220947266\n",
      "Epoch:  359\n",
      "Training loss:  0.6398087739944458\n",
      "Validation loss:  0.6940975785255432\n",
      "Epoch:  360\n",
      "Training loss:  0.6545341610908508\n",
      "Validation loss:  0.6783990859985352\n",
      "Epoch:  361\n",
      "Training loss:  0.6723383665084839\n",
      "Validation loss:  0.6762000322341919\n",
      "Epoch:  362\n",
      "Training loss:  0.6442236304283142\n",
      "Validation loss:  1.148901343345642\n",
      "Epoch:  363\n",
      "Training loss:  0.6683700680732727\n",
      "Validation loss:  0.781121551990509\n",
      "Epoch:  364\n",
      "Training loss:  0.6623355150222778\n",
      "Validation loss:  0.6297779083251953\n",
      "Epoch:  365\n",
      "Training loss:  0.6137475371360779\n",
      "Validation loss:  0.678809642791748\n",
      "Epoch:  366\n",
      "Training loss:  0.6547433733940125\n",
      "Validation loss:  0.6576134562492371\n",
      "Epoch:  367\n",
      "Training loss:  0.5933581590652466\n",
      "Validation loss:  0.6898963451385498\n",
      "Epoch:  368\n",
      "Training loss:  0.6904740929603577\n",
      "Validation loss:  0.6484355330467224\n",
      "Epoch:  369\n",
      "Training loss:  0.6530453562736511\n",
      "Validation loss:  0.5810875296592712\n",
      "Epoch:  370\n",
      "Training loss:  0.6402941346168518\n",
      "Validation loss:  0.7127581834793091\n",
      "Epoch:  371\n",
      "Training loss:  0.648563027381897\n",
      "Validation loss:  0.7592178583145142\n",
      "Epoch:  372\n",
      "Training loss:  0.7171763181686401\n",
      "Validation loss:  0.7421047687530518\n",
      "Epoch:  373\n",
      "Training loss:  0.715229332447052\n",
      "Validation loss:  0.7575623989105225\n",
      "Epoch:  374\n",
      "Training loss:  0.6421356201171875\n",
      "Validation loss:  0.7102339267730713\n",
      "Epoch:  375\n",
      "Training loss:  0.6193545460700989\n",
      "Validation loss:  0.6448966264724731\n",
      "Epoch:  376\n",
      "Training loss:  0.6551741361618042\n",
      "Validation loss:  1.1782069206237793\n",
      "Epoch:  377\n",
      "Training loss:  0.6150648593902588\n",
      "Validation loss:  0.7059052586555481\n",
      "Epoch:  378\n",
      "Training loss:  0.6502225399017334\n",
      "Validation loss:  0.7004604935646057\n",
      "Epoch:  379\n",
      "Training loss:  0.6481906175613403\n",
      "Validation loss:  0.6880943775177002\n",
      "Epoch:  380\n",
      "Training loss:  0.7101669311523438\n",
      "Validation loss:  0.6948853731155396\n",
      "Epoch:  381\n",
      "Training loss:  0.6562952995300293\n",
      "Validation loss:  0.8232998251914978\n",
      "Epoch:  382\n",
      "Training loss:  0.6783873438835144\n",
      "Validation loss:  1.076324462890625\n",
      "Epoch:  383\n",
      "Training loss:  0.6488749384880066\n",
      "Validation loss:  0.689568281173706\n",
      "Epoch:  384\n",
      "Training loss:  0.6434884667396545\n",
      "Validation loss:  1.240563154220581\n",
      "Epoch:  385\n",
      "Training loss:  0.6365554928779602\n",
      "Validation loss:  0.8119596242904663\n",
      "Epoch:  386\n",
      "Training loss:  0.6373518109321594\n",
      "Validation loss:  0.77325439453125\n",
      "Epoch:  387\n",
      "Training loss:  0.6802797913551331\n",
      "Validation loss:  0.6829091310501099\n",
      "Epoch:  388\n",
      "Training loss:  0.6554049253463745\n",
      "Validation loss:  0.6221864819526672\n",
      "Epoch:  389\n",
      "Training loss:  0.6145569086074829\n",
      "Validation loss:  0.685425877571106\n",
      "Epoch:  390\n",
      "Training loss:  0.7322367429733276\n",
      "Validation loss:  0.8265443444252014\n",
      "Epoch:  391\n",
      "Training loss:  0.7284847497940063\n",
      "Validation loss:  0.6500887870788574\n",
      "Epoch:  392\n",
      "Training loss:  0.6703239679336548\n",
      "Validation loss:  0.6989525556564331\n",
      "Epoch:  393\n",
      "Training loss:  0.6859825849533081\n",
      "Validation loss:  0.7404362559318542\n",
      "Epoch:  394\n",
      "Training loss:  0.6285874843597412\n",
      "Validation loss:  0.6510783433914185\n",
      "Epoch:  395\n",
      "Training loss:  0.6932295560836792\n",
      "Validation loss:  0.845916748046875\n",
      "Epoch:  396\n",
      "Training loss:  0.6291486024856567\n",
      "Validation loss:  0.7067095637321472\n",
      "Epoch:  397\n",
      "Training loss:  0.6214730143547058\n",
      "Validation loss:  0.7194190621376038\n",
      "Epoch:  398\n",
      "Training loss:  0.6107100248336792\n",
      "Validation loss:  0.9469200372695923\n",
      "Epoch:  399\n",
      "Training loss:  0.6069017052650452\n",
      "Validation loss:  0.6505432724952698\n",
      "Epoch:  400\n",
      "Training loss:  0.6389991641044617\n",
      "Validation loss:  0.7405279278755188\n",
      "Epoch:  401\n",
      "Training loss:  0.6568548083305359\n",
      "Validation loss:  0.747795045375824\n",
      "Epoch:  402\n",
      "Training loss:  0.6815656423568726\n",
      "Validation loss:  0.665655255317688\n",
      "Epoch:  403\n",
      "Training loss:  0.6683496832847595\n",
      "Validation loss:  0.984499990940094\n",
      "Epoch:  404\n",
      "Training loss:  0.6439059972763062\n",
      "Validation loss:  0.7177496552467346\n",
      "Epoch:  405\n",
      "Training loss:  0.6686886548995972\n",
      "Validation loss:  0.6869872212409973\n",
      "Epoch:  406\n",
      "Training loss:  0.639832079410553\n",
      "Validation loss:  1.2065629959106445\n",
      "Epoch:  407\n",
      "Training loss:  0.6778794527053833\n",
      "Validation loss:  0.6854124665260315\n",
      "Epoch:  408\n",
      "Training loss:  0.6385496854782104\n",
      "Validation loss:  0.7076501846313477\n",
      "Epoch:  409\n",
      "Training loss:  0.6502379179000854\n",
      "Validation loss:  0.7032649517059326\n",
      "Epoch:  410\n",
      "Training loss:  0.6693698763847351\n",
      "Validation loss:  0.5754834413528442\n",
      "Epoch:  411\n",
      "Training loss:  0.6108318567276001\n",
      "Validation loss:  1.5577635765075684\n",
      "Epoch:  412\n",
      "Training loss:  0.6454287171363831\n",
      "Validation loss:  0.9936270117759705\n",
      "Epoch:  413\n",
      "Training loss:  0.6212256550788879\n",
      "Validation loss:  0.6126731634140015\n",
      "Epoch:  414\n",
      "Training loss:  0.6530855298042297\n",
      "Validation loss:  0.6228209137916565\n",
      "Epoch:  415\n",
      "Training loss:  0.7177063822746277\n",
      "Validation loss:  0.6466932892799377\n",
      "Epoch:  416\n",
      "Training loss:  0.6474276185035706\n",
      "Validation loss:  0.7027122378349304\n",
      "Epoch:  417\n",
      "Training loss:  0.6971195936203003\n",
      "Validation loss:  0.8933651447296143\n",
      "Epoch:  418\n",
      "Training loss:  0.6712242364883423\n",
      "Validation loss:  0.7980400919914246\n",
      "Epoch:  419\n",
      "Training loss:  0.6863648891448975\n",
      "Validation loss:  0.6959294080734253\n",
      "Epoch:  420\n",
      "Training loss:  0.6940145492553711\n",
      "Validation loss:  0.7462068200111389\n",
      "Epoch:  421\n",
      "Training loss:  0.6818658113479614\n",
      "Validation loss:  0.6834230422973633\n",
      "Epoch:  422\n",
      "Training loss:  0.6489207148551941\n",
      "Validation loss:  0.7704762816429138\n",
      "Epoch:  423\n",
      "Training loss:  0.6680823564529419\n",
      "Validation loss:  1.2998535633087158\n",
      "Epoch:  424\n",
      "Training loss:  0.6939097046852112\n",
      "Validation loss:  0.9389529228210449\n",
      "Epoch:  425\n",
      "Training loss:  0.647126317024231\n",
      "Validation loss:  0.71487957239151\n",
      "Epoch:  426\n",
      "Training loss:  0.6693633198738098\n",
      "Validation loss:  0.658473551273346\n",
      "Epoch:  427\n",
      "Training loss:  0.6325694918632507\n",
      "Validation loss:  0.6780472993850708\n",
      "Epoch:  428\n",
      "Training loss:  0.5820934176445007\n",
      "Validation loss:  0.6628014445304871\n",
      "Epoch:  429\n",
      "Training loss:  0.6500414609909058\n",
      "Validation loss:  0.636438250541687\n",
      "Epoch:  430\n",
      "Training loss:  0.6570103168487549\n",
      "Validation loss:  0.9056903719902039\n",
      "Epoch:  431\n",
      "Training loss:  0.6777569055557251\n",
      "Validation loss:  0.6894637942314148\n",
      "Epoch:  432\n",
      "Training loss:  0.6285692453384399\n",
      "Validation loss:  0.6997044086456299\n",
      "Epoch:  433\n",
      "Training loss:  0.5700883865356445\n",
      "Validation loss:  0.8037989139556885\n",
      "Epoch:  434\n",
      "Training loss:  0.6519612073898315\n",
      "Validation loss:  0.6493675708770752\n",
      "Epoch:  435\n",
      "Training loss:  0.6684347987174988\n",
      "Validation loss:  0.6830747127532959\n",
      "Epoch:  436\n",
      "Training loss:  0.6260230541229248\n",
      "Validation loss:  0.7308814525604248\n",
      "Epoch:  437\n",
      "Training loss:  0.6724178194999695\n",
      "Validation loss:  0.7160089015960693\n",
      "Epoch:  438\n",
      "Training loss:  0.6934782862663269\n",
      "Validation loss:  0.9253076314926147\n",
      "Epoch:  439\n",
      "Training loss:  0.6620953679084778\n",
      "Validation loss:  0.7270383834838867\n",
      "Epoch:  440\n",
      "Training loss:  0.6334906816482544\n",
      "Validation loss:  0.5917699933052063\n",
      "Epoch:  441\n",
      "Training loss:  0.6646910309791565\n",
      "Validation loss:  0.6799066066741943\n",
      "Epoch:  442\n",
      "Training loss:  0.6628780961036682\n",
      "Validation loss:  0.66553795337677\n",
      "Epoch:  443\n",
      "Training loss:  0.6338249444961548\n",
      "Validation loss:  0.7090175747871399\n",
      "Epoch:  444\n",
      "Training loss:  0.6199761629104614\n",
      "Validation loss:  1.051430106163025\n",
      "Epoch:  445\n",
      "Training loss:  0.6130918860435486\n",
      "Validation loss:  0.8530091047286987\n",
      "Epoch:  446\n",
      "Training loss:  0.6481295824050903\n",
      "Validation loss:  0.6191122531890869\n",
      "Epoch:  447\n",
      "Training loss:  0.6796779036521912\n",
      "Validation loss:  0.6705771684646606\n",
      "Epoch:  448\n",
      "Training loss:  0.6189313530921936\n",
      "Validation loss:  0.6676126718521118\n",
      "Epoch:  449\n",
      "Training loss:  0.5723394155502319\n",
      "Validation loss:  0.8162801265716553\n",
      "Epoch:  450\n",
      "Training loss:  0.6735891699790955\n",
      "Validation loss:  0.6627137660980225\n",
      "Epoch:  451\n",
      "Training loss:  0.6472204923629761\n",
      "Validation loss:  0.6103512644767761\n",
      "Epoch:  452\n",
      "Training loss:  0.7193713784217834\n",
      "Validation loss:  0.6788396239280701\n",
      "Epoch:  453\n",
      "Training loss:  0.6454688310623169\n",
      "Validation loss:  0.6702961921691895\n",
      "Epoch:  454\n",
      "Training loss:  0.6106038093566895\n",
      "Validation loss:  1.1590313911437988\n",
      "Epoch:  455\n",
      "Training loss:  0.59321129322052\n",
      "Validation loss:  0.7049732208251953\n",
      "Epoch:  456\n",
      "Training loss:  0.6463737487792969\n",
      "Validation loss:  0.6883043646812439\n",
      "Epoch:  457\n",
      "Training loss:  0.6669194102287292\n",
      "Validation loss:  0.5950551629066467\n",
      "Epoch:  458\n",
      "Training loss:  0.6549652814865112\n",
      "Validation loss:  0.7100363969802856\n",
      "Epoch:  459\n",
      "Training loss:  0.7209833860397339\n",
      "Validation loss:  0.5435294508934021\n",
      "Epoch:  460\n",
      "Training loss:  0.6775094270706177\n",
      "Validation loss:  0.7416363954544067\n",
      "Epoch:  461\n",
      "Training loss:  0.6907830238342285\n",
      "Validation loss:  0.615986704826355\n",
      "Epoch:  462\n",
      "Training loss:  0.8285233378410339\n",
      "Validation loss:  0.6855244040489197\n",
      "Epoch:  463\n",
      "Training loss:  0.5880421996116638\n",
      "Validation loss:  0.8479164838790894\n",
      "Epoch:  464\n",
      "Training loss:  0.6502386927604675\n",
      "Validation loss:  0.6762224435806274\n",
      "Epoch:  465\n",
      "Training loss:  0.6141091585159302\n",
      "Validation loss:  0.6523356437683105\n",
      "Epoch:  466\n",
      "Training loss:  0.6607796549797058\n",
      "Validation loss:  0.8195104598999023\n",
      "Epoch:  467\n",
      "Training loss:  0.627812922000885\n",
      "Validation loss:  0.7183534502983093\n",
      "Epoch:  468\n",
      "Training loss:  0.6018293499946594\n",
      "Validation loss:  0.6493227481842041\n",
      "Epoch:  469\n",
      "Training loss:  0.6799384355545044\n",
      "Validation loss:  0.6326457858085632\n",
      "Epoch:  470\n",
      "Training loss:  0.6273645758628845\n",
      "Validation loss:  0.7419095039367676\n",
      "Epoch:  471\n",
      "Training loss:  0.6387041807174683\n",
      "Validation loss:  0.6428025364875793\n",
      "Epoch:  472\n",
      "Training loss:  0.745917558670044\n",
      "Validation loss:  0.6530762314796448\n",
      "Epoch:  473\n",
      "Training loss:  0.6489071846008301\n",
      "Validation loss:  0.7282262444496155\n",
      "Epoch:  474\n",
      "Training loss:  0.615268886089325\n",
      "Validation loss:  0.6982948780059814\n",
      "Epoch:  475\n",
      "Training loss:  0.6766424775123596\n",
      "Validation loss:  1.0002630949020386\n",
      "Epoch:  476\n",
      "Training loss:  0.6194272041320801\n",
      "Validation loss:  0.8315047025680542\n",
      "Epoch:  477\n",
      "Training loss:  0.644356369972229\n",
      "Validation loss:  0.68927001953125\n",
      "Epoch:  478\n",
      "Training loss:  0.700239360332489\n",
      "Validation loss:  0.6749254465103149\n",
      "Epoch:  479\n",
      "Training loss:  0.5951448082923889\n",
      "Validation loss:  0.796941339969635\n",
      "Epoch:  480\n",
      "Training loss:  0.6460496187210083\n",
      "Validation loss:  0.6682827472686768\n",
      "Epoch:  481\n",
      "Training loss:  0.607791543006897\n",
      "Validation loss:  0.728492259979248\n",
      "Epoch:  482\n",
      "Training loss:  0.7037431001663208\n",
      "Validation loss:  0.6891573667526245\n",
      "Epoch:  483\n",
      "Training loss:  0.6594022512435913\n",
      "Validation loss:  1.122502088546753\n",
      "Epoch:  484\n",
      "Training loss:  0.6336742043495178\n",
      "Validation loss:  1.1102107763290405\n",
      "Epoch:  485\n",
      "Training loss:  0.6529632806777954\n",
      "Validation loss:  0.7112419605255127\n",
      "Epoch:  486\n",
      "Training loss:  0.6707638502120972\n",
      "Validation loss:  1.1979155540466309\n",
      "Epoch:  487\n",
      "Training loss:  0.6834388971328735\n",
      "Validation loss:  0.8248605728149414\n",
      "Epoch:  488\n",
      "Training loss:  0.6437891721725464\n",
      "Validation loss:  0.8495752811431885\n",
      "Epoch:  489\n",
      "Training loss:  0.6356440186500549\n",
      "Validation loss:  1.2360517978668213\n",
      "Epoch:  490\n",
      "Training loss:  0.6410353183746338\n",
      "Validation loss:  0.7174519896507263\n",
      "Epoch:  491\n",
      "Training loss:  0.652255117893219\n",
      "Validation loss:  0.7236356735229492\n",
      "Epoch:  492\n",
      "Training loss:  0.660012423992157\n",
      "Validation loss:  1.3512085676193237\n",
      "Epoch:  493\n",
      "Training loss:  0.6468642950057983\n",
      "Validation loss:  0.663032054901123\n",
      "Epoch:  494\n",
      "Training loss:  0.6247440576553345\n",
      "Validation loss:  0.8232864141464233\n",
      "Epoch:  495\n",
      "Training loss:  0.6255738735198975\n",
      "Validation loss:  0.6773748397827148\n",
      "Epoch:  496\n",
      "Training loss:  0.6957148313522339\n",
      "Validation loss:  0.6471351385116577\n",
      "Epoch:  497\n",
      "Training loss:  0.6242554187774658\n",
      "Validation loss:  0.7213733196258545\n",
      "Epoch:  498\n",
      "Training loss:  0.6264822483062744\n",
      "Validation loss:  0.7819147706031799\n",
      "Epoch:  499\n",
      "Training loss:  0.6659051179885864\n",
      "Validation loss:  0.7250863313674927\n",
      "Epoch:  500\n",
      "Training loss:  0.6523424386978149\n",
      "Validation loss:  0.7376663088798523\n",
      "Elapsed model training time:\n",
      "29.71 minutes\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train RNN model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_loss, validation_loss = Torch_LSTM_RNN.train_model(train_dataloader = train_dataloader,\n",
    "                                                       validation_dataloader = validation_dataloader,\n",
    "                                                       num_epochs = num_epochs,\n",
    "                                                       loss_kind = loss_kind,\n",
    "                                                       optimizer = optimizer)\n",
    "\n",
    "# print train time\n",
    "elapsed_time = ((time.time() - start_time) / 60)\n",
    "print()\n",
    "print(\"Elapsed model training time:\\n{:.2f} minutes\".format(elapsed_time))\n",
    "\n",
    "# plot loss curves\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), train_loss, label = 'Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), validation_loss, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e3894-efa0-4fc7-9ec9-59055a35d5cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6. Calculate and report the performance of your model on the training and test set. 15 points\n",
    "- Calculate the accuracies on the training and test sets\n",
    "- Print out the confusion matrix of model results on the test set: https://scikit-learn.org/dev/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05175dbb-5195-48a1-8d41-3dea59a1fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      " 0.5738\n",
      "\n",
      "Test accuracy:\n",
      " 0.5718\n",
      "\n",
      "Confusion matrix for train set:\n",
      " [[ 3912  8527]\n",
      " [ 2128 10433]]\n",
      "\n",
      "Confusion matrix for test set:\n",
      " [[ 3866  8573]\n",
      " [ 2132 10429]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "train_accuracy, Y_train_hat, Y_train = Torch_LSTM_RNN.evaluate(train_dataloader)\n",
    "test_accuracy, Y_test_hat, Y_test = Torch_LSTM_RNN.evaluate(train_dataloader)\n",
    "\n",
    "# print accuracies\n",
    "\n",
    "print(\"Training accuracy:\\n\", train_accuracy)\n",
    "print()\n",
    "print(\"Test accuracy:\\n\", test_accuracy)\n",
    "print()\n",
    "\n",
    "# confusion matrices\n",
    "\n",
    "print(\"Confusion matrix for train set:\\n\", confusion_matrix(Y_train, Y_train_hat))\n",
    "print()\n",
    "print(\"Confusion matrix for test set:\\n\", confusion_matrix(Y_test, Y_test_hat))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49ff39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36792e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c0d9d3",
   "metadata": {},
   "source": [
    "# Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e26ece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Training data shape\n",
    "sequence_length = 256  # Length of each sequence\n",
    "\n",
    "# Model hyperparameters\n",
    "vocab_size = X_train.max()+1  # Vocabulary size (number of unique tokens or words)\n",
    "embedding_dim = 64  # Size of embedding vectors\n",
    "hidden_units = 10  # Number of units in LSTM layer\n",
    "output_units = 1  # Output size (binary classification)\n",
    "lr = 0.001  # Learning rate\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding Layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))#, input_length=sequence_length))\n",
    "\n",
    "# LSTM Layer\n",
    "model.add(LSTM(hidden_units, return_sequences=False))\n",
    "\n",
    "# Dense Output Layer\n",
    "model.add(Dense(output_units, activation='sigmoid'))  # Sigmoid activation for binary classification...\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08c4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 65ms/step - accuracy: 0.5046 - loss: 0.6932 - val_accuracy: 0.4999 - val_loss: 0.6928\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.5254 - loss: 0.6884 - val_accuracy: 0.5417 - val_loss: 0.6769\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.5581 - loss: 0.6511 - val_accuracy: 0.5090 - val_loss: 0.6962\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.5745 - loss: 0.6233 - val_accuracy: 0.5403 - val_loss: 0.6893\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.5752 - loss: 0.6046 - val_accuracy: 0.5280 - val_loss: 0.6970\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.5972 - loss: 0.5956 - val_accuracy: 0.6363 - val_loss: 0.7261\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.7347 - loss: 0.5660 - val_accuracy: 0.7446 - val_loss: 0.5599\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.8410 - loss: 0.4141 - val_accuracy: 0.8003 - val_loss: 0.4883\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.8986 - loss: 0.3008 - val_accuracy: 0.8263 - val_loss: 0.4414\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9397 - loss: 0.1959 - val_accuracy: 0.8400 - val_loss: 0.4246\n",
      "\n",
      "Elapsed model training time:\n",
      "2.03 minutes\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example Training Data\n",
    "import numpy as np\n",
    "num_epochs = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "histroy = model.fit(X_train, Y_train, epochs= num_epochs,validation_data=(X_validation,Y_validation),\n",
    "                    batch_size=128, verbose=1)\n",
    "\n",
    "# print train time\n",
    "elapsed_time = ((time.time() - start_time) / 60)\n",
    "print()\n",
    "print(\"Elapsed model training time:\\n{:.2f} minutes\".format(elapsed_time))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(histroy.history[\"loss\"], label = \"Training Loss\")\n",
    "plt.plot(histroy.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Losses of Keras LSTM RNN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d7d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "\n",
      "Using accuracy score:\n",
      "\n",
      "Training accuracy: 0.96688\n",
      "Test accuracy: 0.8446666666666667\n",
      "\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.1385\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8444 - loss: 0.4163\n",
      "\n",
      "Using evaluate:\n",
      "Training accuracy: 0.9668800234794617\n",
      "Test accuracy: 0.8446666598320007\n",
      "\n",
      "Confusion matrix for train set:\n",
      " [[12086   353]\n",
      " [  475 12086]]\n",
      "\n",
      "Confusion matrix for test set:\n",
      " [[6414 1109]\n",
      " [1221 6256]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "\n",
    "Y_train_hat = model.predict(X_train)\n",
    "Y_test_hat = model.predict(X_test)\n",
    "Y_train_hat = (Y_train_hat > 0.5).astype(int)\n",
    "Y_test_hat = (Y_test_hat > 0.5).astype(int)\n",
    "\n",
    "train_accuracy = accuracy_score(Y_train, Y_train_hat)\n",
    "test_accuracy = accuracy_score(Y_test, Y_test_hat)\n",
    "\n",
    "print()\n",
    "\n",
    "# print accuracies using accuracy score\n",
    "print(\"Using accuracy score:\")\n",
    "print()\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print()\n",
    "\n",
    "# print accuracies using evaluate\n",
    "train_loss, train_accuracy = model.evaluate(X_train, Y_train)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print()\n",
    "print(\"Using evaluate:\")\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print()\n",
    "\n",
    "# confusion matrices\n",
    "print(\"Confusion matrix for train set:\\n\", confusion_matrix(Y_train, Y_train_hat))\n",
    "print()\n",
    "print(\"Confusion matrix for test set:\\n\", confusion_matrix(Y_test, Y_test_hat))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
