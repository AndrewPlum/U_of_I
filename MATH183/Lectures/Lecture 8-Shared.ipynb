{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e2f0fc",
   "metadata": {},
   "source": [
    "# Pandas \n",
    "\n",
    "Pandas is a library for data analysis in Python. It provides data structures for efficiently storing large datasets and tools for working with them.\n",
    "\n",
    "Pandas is widely used for data analysis and is an essential library for data scientists, business analysts, and data engineers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511cba4",
   "metadata": {},
   "source": [
    "## Two main data structures\n",
    "\n",
    "- A __Series__ is a one-dimensional labeled array that can hold any data type. \n",
    "\n",
    "- A __DataFrame__ is a 2-dimensional labeled data structure with columns that can be of different data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf14cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data series:\n",
      " 0    10\n",
      "1    40\n",
      "2     3\n",
      "3     1\n",
      "4     6\n",
      "dtype: int64\n",
      "Data type of s: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Series\n",
    "data = [10, 40, 3, 1, 6]\n",
    "s = pd.Series(data)\n",
    "print(\"Data series:\\n\", s)\n",
    "print(\"Data type of s:\", type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11aba41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Quick review on 2D list\n",
    "data = [[1, 2, 3],[4, 5, 6],[7, 8, 9]]\n",
    "print(data)\n",
    "print(data[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6b2cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frame by list \n",
      "    0  1  2\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(\"data frame by list \\n\", df)\n",
    "# DataFrame shape\n",
    "print(df.shape)\n",
    "#print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb752036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frame by dictionary \n",
      "    price  exp date  country\n",
      "0      1         4        7\n",
      "1      2         5        8\n",
      "2      3         6        9\n",
      "3    100      3000        1\n",
      "(4, 3)\n",
      "Index(['price', 'exp date', 'country'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# DataFrame by dictionary\n",
    "\n",
    "data = {'price': [1, 2, 3,100],\n",
    "        'exp date': [4, 5, 6,3000],\n",
    "        'country': [7, 8, 9,1]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"data frame by dictionary \\n\", df)\n",
    "\n",
    "# DataFrame shape\n",
    "print(df.shape)\n",
    "\n",
    "#List all columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f93481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       4\n",
      "1       5\n",
      "2       6\n",
      "3    3000\n",
      "Name: tom, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Selecting columns\n",
    "col = df['tom']\n",
    "print(col)\n",
    "print(type(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b50e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob     1\n",
      "tom     4\n",
      "mary    7\n",
      "Name: 0, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Selecting rows\n",
    "r= df.loc[0]\n",
    "print(r)\n",
    "print(type(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741300db",
   "metadata": {},
   "source": [
    "## Handling with missing data\n",
    "Missing data in Pandas is represented by NaN. Before using the data for any task, one needs to handle the missng values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af969b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a    b  c\n",
      "0  1  4.0  7\n",
      "1  2  NaN  8\n",
      "2  3  6.0  9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = {'a': [1, 2, 3],\n",
    "        'b': [4, np.NaN, 6],\n",
    "        'c': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a932660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a    b  c\n",
      "0  1  4.0  7\n",
      "2  3  6.0  9\n"
     ]
    }
   ],
   "source": [
    "# Drop missing values\n",
    "print(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd03092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a    b  c\n",
      "0  1  4.0  7\n",
      "1  2  NaN  8\n",
      "2  3  6.0  9\n",
      "   a    b  c\n",
      "0  1  4.0  7\n",
      "1  2  0.0  8\n",
      "2  3  6.0  9\n"
     ]
    }
   ],
   "source": [
    "data = {'a': [1, 2, 3],\n",
    "        'b': [4, np.NaN, 6],\n",
    "        'c': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "# Fill missing values\n",
    "print(df.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1f4e6",
   "metadata": {},
   "source": [
    "## Concatenating\n",
    "\n",
    "__pd.concat__ is used for concatenating DataFrames along either the rows or columns axis. This function can be used to simply stack DataFrames on top of each other (row-wise concatenation) or side by side (column-wise concatenation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f018b982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  A4  B4  C4  D4\n",
      "5  A5  B5  C5  D5\n",
      "6  A6  B6  C6  D6\n",
      "7  A7  B7  C7  D7\n"
     ]
    }
   ],
   "source": [
    "# Row-wise concatenation\n",
    "\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},                    \n",
    "                   index=[0, 1, 2, 3])\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                   index=[4, 5, 6, 7])\n",
    "df = pd.concat([df1, df2])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a991d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "    E   F\n",
      "0  E4  F4\n",
      "1  E5  F5\n",
      "2  E6  F6\n",
      "3  E7  F7\n",
      "    A   B   C   D   E   F\n",
      "0  A0  B0  C0  D0  E4  F4\n",
      "1  A1  B1  C1  D1  E5  F5\n",
      "2  A2  B2  C2  D2  E6  F6\n",
      "3  A3  B3  C3  D3  E7  F7\n"
     ]
    }
   ],
   "source": [
    "# Row-wise concatenation\n",
    "\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "df2 = pd.DataFrame({'E': ['E4', 'E5', 'E6', 'E7'],\n",
    "                    'F': ['F4', 'F5', 'F6', 'F7']}\n",
    "                    )\n",
    "print(df1)\n",
    "print(df2)\n",
    "df = pd.concat([df1, df2],axis =1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad4ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "0     Spark  20000      NaN       NaN\n",
      "1   PySpark  25000      NaN       NaN\n",
      "2    Python  22000      NaN       NaN\n",
      "3    Pandas  24000      NaN       NaN\n",
      "0      Unix  25000      NaN       NaN\n",
      "1    Hadoop  25200      NaN       NaN\n",
      "2  Hyperion  24500      NaN       NaN\n",
      "3      Java  24900      NaN       NaN\n",
      "0       NaN    NaN    30day    1000.0\n",
      "1       NaN    NaN   40days    2300.0\n",
      "2       NaN    NaN   35days    2500.0\n",
      "3       NaN    NaN   60days    2000.0\n",
      "4       NaN    NaN   55days    3000.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenating multiple DataFrames\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Courses': [\"Spark\", \"PySpark\", \"Python\", \"Pandas\"],\n",
    "                    'Fee' : ['20000', '25000', '22000', '24000']}) \n",
    "  \n",
    "df1 = pd.DataFrame({'Courses': [\"Unix\", \"Hadoop\", \"Hyperion\", \"Java\"],\n",
    "                    'Fee': ['25000', '25200', '24500', '24900']})\n",
    "  \n",
    "df2 = pd.DataFrame({'Duration':['30day','40days','35days','60days','55days'],\n",
    "                    'Discount':[1000,2300,2500,2000,3000]})\n",
    "  \n",
    "# Appending multiple DataFrame\n",
    "df3 = pd.concat([df, df1, df2])\n",
    "#df3 = pd.concat([df, df1, df2])\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24640d2",
   "metadata": {},
   "source": [
    "__Practice Problem:__ Find a way to generate the following Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f92163ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0  1.0  1.0  NaN  NaN\n",
      "1  1.0  1.0  NaN  NaN\n",
      "2  1.0  1.0  NaN  NaN\n",
      "0  NaN  NaN  2.0  2.0\n",
      "1  NaN  NaN  2.0  2.0\n",
      "2  NaN  NaN  2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "data1 = {\"A\":[1,1,1], \"B\":[1,1,1]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "data2 = {\"C\":[2,2,2], \"D\":[2,2,2]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df = pd.concat([df1,df2])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ef5da",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "__pd.merge__ is a function in the Pandas library that is used to merge two or more DataFrames based on the values of one or more common columns (known as \"keys\"). The function provides options for specifying the type of join (inner, outer, left, right), handling of overlapping column names, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b216507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  comon    A    B    C    D\n",
      "0    K0   A0   B0   C0   D0\n",
      "1    K1   A1   B1   C1   D1\n",
      "2    K2   A2   B2   C2   D2\n",
      "3    K3   A3   B3  NaN  NaN\n",
      "4    K4  NaN  NaN   C3   D3\n"
     ]
    }
   ],
   "source": [
    "# Creating sample dataframes\n",
    "df1 = pd.DataFrame({'comon': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "df2 = pd.DataFrame({'comon': ['K0', 'K1', 'K2', 'K4'],\n",
    "                     'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Performing an outer join on the \"key\" column\n",
    "#result = pd.merge(df1, df2, on='key', how='inner')\n",
    "result = pd.merge(df1, df2, on='comon',how = 'outer')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sample dataframes\n",
    "df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K4'],\n",
    "                     'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Performing an outer join on the \"key\" column\n",
    "result = pd.merge(df1, df2, on='key', how='outer')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb1d7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Join Result:\n",
      "  key   A   B    C    D\n",
      "0  K0  A0  B0   C0   D0\n",
      "1  K1  A1  B1   C1   D1\n",
      "2  K2  A2  B2   C2   D2\n",
      "3  K3  A3  B3  NaN  NaN\n",
      "Right Join Result:\n",
      "  key    A    B   C   D\n",
      "0  K0   A0   B0  C0  D0\n",
      "1  K1   A1   B1  C1  D1\n",
      "2  K2   A2   B2  C2  D2\n",
      "3  K4  NaN  NaN  C3  D3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating sample dataframes\n",
    "df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "\n",
    "df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K4'],\n",
    "                     'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "# Performing a left join on the \"key\" column\n",
    "left_result = pd.merge(df1, df2, on='key', how='left')\n",
    "print(\"Left Join Result:\")\n",
    "print(left_result)\n",
    "\n",
    "# Performing a right join on the \"key\" column\n",
    "right_result = pd.merge(df1, df2, on='key', how='right')\n",
    "print(\"Right Join Result:\")\n",
    "print(right_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0f799",
   "metadata": {},
   "source": [
    "NOTE: the \"print\" command doesn't output good-looking DataFrame. Instead, you just can call out the name of the DataFrame or use the command \"df.head()\" (this will print out the firt five row of the frame). See example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1efaf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0</td>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K1</td>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K2</td>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key    A    B   C   D\n",
       "0  K0   A0   B0  C0  D0\n",
       "1  K1   A1   B1  C1  D1\n",
       "2  K2   A2   B2  C2  D2\n",
       "3  K4  NaN  NaN  C3  D3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd255d7",
   "metadata": {},
   "source": [
    "## pd.merge vs pd.concat\n",
    "\n",
    "- __pd.merge__ is used for combining two or more DataFrames based on the values in one or more common columns, also known as a \"database-style\" join. This function can perform different types of joins such as inner, outer, left, and right joins. It allows you to combine DataFrames based on the values in specific columns, which can be useful when you have different columns in different DataFrames that have the same meaning or when you want to merge only the rows that have matching values in a specific column.\n",
    "\n",
    "- __pd.concat__ is used for concatenating DataFrames along either the rows or columns axis. This function can be used to simply stack DataFrames on top of each other (row-wise concatenation) or side by side (column-wise concatenation). Unlike pd.merge, pd.concat does not require any common columns between the DataFrames and does not perform any merging based on values in a specific column.\n",
    "\n",
    "- In general, you should use __pd.merge__ when you want to merge DataFrames based on the values in a common column, and use __pd.concat__ when you want to concatenate DataFrames along either the rows or columns axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba744e8",
   "metadata": {},
   "source": [
    "## Check out ticket\n",
    "\n",
    "__Problem 1:__ The cafeteria at UI has a data file to store the following information of its customer: (1) phone number, (2) list of items they have purchased, (3) unit price, (4) quantity (5) date of purchase (6) and time of each purchase. See attached image \"cafe.png\". Generate such a file with $20$ rows (make it as diverse as possible).\n",
    "\n",
    "__Problem 2:__ The REC center at UI has a data file to store the following information of its members: (1) phone number, (2) date of visit (3) starting time of visit, (4) ending time of visit. Make such as data file with $20$ rows.\n",
    "\n",
    "__Problem 3:__ The university wants to make a data file that contains the activities of both its Cafeteria and REC center. Write the code to generate such data file.\n",
    "\n",
    "__Problem 4:__ The REC center wants to see the eating habits of its members to make food recommendation. Write the code to combine the data file for such purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4758ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone</th>\n",
       "      <th>items</th>\n",
       "      <th>unit price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208-310-4288</td>\n",
       "      <td>coffee</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec 12, 2022</td>\n",
       "      <td>9:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208-310-4288</td>\n",
       "      <td>baggle</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec 12, 2022</td>\n",
       "      <td>9:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208-310-4288</td>\n",
       "      <td>baggle</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec 22, 2022</td>\n",
       "      <td>10:01 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          phone   items  unit price  quantity          date      time\n",
       "0  208-310-4288  coffee           5         1  Dec 12, 2022   9:00 AM\n",
       "1  208-310-4288  baggle           6         1  Dec 12, 2022   9:00 AM\n",
       "2  208-310-4288  baggle           5         1  Dec 22, 2022  10:01 AM"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\"phone\": ['208-310-4288','208-310-4288','208-310-4288'], \n",
    "        \"items\":[\"coffee\", \"baggle\", \"baggle\"] ,\n",
    "        \"unit price\":[5,6,5],\n",
    "        \"quantity\": [1,1,1],\n",
    "        \"date\":[\"Dec 12, 2022\",\"Dec 12, 2022\",\"Dec 22, 2022\"],\n",
    "        \"time\":[\"9:00 AM\",\"9:00 AM\",\"10:01 AM\"]\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52d275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[49744]: Class WebSwapCGLLayer is implemented in both /System/Library/Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/Versions/A/Frameworks/libANGLE-shared.dylib (0x7ffb5e1e4ec8) and /Applications/Google Chrome.app/Contents/Frameworks/Google Chrome Framework.framework/Versions/109.0.5414.119/Libraries/libGLESv2.dylib (0x10ffa9880). One of the two will be used. Which one is undefined.\n",
      "[0207/112323.746782:INFO:headless_shell.cc(223)] 71189 bytes written to file /var/folders/cd/4zjhmhws6f38td1n6ddw_3pc0000gn/T/tmpzcs2c1p0/temp.png\n"
     ]
    }
   ],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.export(df,\"cafe.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
